{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc26ebe0-9fe4-49ce-9970-c45aa5c280db",
   "metadata": {},
   "source": [
    "#### El cliente ha corroborado que podemos manejar RDD's pero el CORE a utilizar será dataframes, nos han solicitado crear algunas funciones para cargar archivos en formato csv y almacenarlos en formato parquet. ¿Por qué en parquet? Hecha un ojo a esto (vendrá en la evaluación final):\n",
    "#### https://www.databricks.com/glossary/what-is-parquet\n",
    "#### Cuando termines resuelve cada actividad planteada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba45903-1c28-444b-9af0-6442a36468a6",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO: Crear sparkSession con appName \"ejercicio_4\", y master \"local[*]\", almacenar sesion de spark en una variable llamada \"spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71db4bec-ce2a-4b44-98d0-4fbdab40ff18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@4ccd5e24\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@4ccd5e24"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame}\n",
    "\n",
    "val spark = SparkSession.builder().appName(\"ejercicio_4\").master(\"local[*]\").getOrCreate()\n",
    "//... Inicia tu sesion de spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe5c3ab-3303-4e65-bb34-087721dce086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@61ae1b03\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Some(http://23LAP5CD20860NP.indra.es:4043)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "val sc = spark.sparkContext\n",
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96f213c-5230-4a4d-9b01-d28e073d0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "assert(spark.isInstanceOf[SparkSession])\n",
    "assert(spark.sparkContext.getConf.get(\"spark.master\") == \"local[*]\")\n",
    "assert(spark.sparkContext.getConf.get(\"spark.app.name\") == \"ejercicio_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c7529-e81d-4bc4-b1b4-abfe69e4b6a5",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    Crear un método para leer un archivo en formato csv, no inferir el esquema, los archivos si incluyen header, el separador es \",\"\n",
    "- ##### retorna ->  dataframe correspondiente a la lectura\n",
    "- ##### firma ->    def readCsv(path: String): DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "636335bd-d238-410c-ab45-bcdb6c732fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readCsv: (path: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def readCsv(path: String): DataFrame = {\n",
    "    spark.read\n",
    "        .option(\"inferSchema\",\"false\")\n",
    "        .option(\"header\",\"true\")\n",
    "        .option(\"delimiter\",\",\")\n",
    "        .csv(path)\n",
    "}\n",
    "    // agrega lectura de dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7668abb-38b9-417a-a381-e9f28fc0f74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cod_client: string (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- edad: string (nullable = true)\n",
      " |-- provincia: string (nullable = true)\n",
      " |-- cod_postal: string (nullable = true)\n",
      " |-- vip: string (nullable = true)\n",
      "\n",
      "+----------+-------+----+---------+----------+-----+\n",
      "|cod_client| nombre|edad|provincia|cod_postal|  vip|\n",
      "+----------+-------+----+---------+----------+-----+\n",
      "|     00001|  Julen|  31| Valencia|     23700|false|\n",
      "|     00002| Javier|  58|     Ja?n|     08728| true|\n",
      "|     00003| Carlos|  48|  Sevilla|     28757| true|\n",
      "|     00004|  Maria|  38|   Gerona|     18393| true|\n",
      "|     00005|Ernesto|  22|  C?ceres|     13950|false|\n",
      "|     00006|  Luisa|  43|   Murcia|     23940| true|\n",
      "|     00007|   Raul|  51|    ?lava|     09030|false|\n",
      "+----------+-------+----+---------+----------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "clientsDF = [cod_client: string, nombre: string ... 4 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "TestPath: String = ../../resources/data/csv/\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[cod_client: string, nombre: string ... 4 more fields]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Celdas de prueba:\n",
    "val TestPath: String = \"../../resources/data/csv/\"\n",
    "\n",
    "val clientsDF: DataFrame = readCsv(TestPath + \"clients.csv\")\n",
    "//val contractsDF: DataFrame = readCsv(TestPath + \"contracts.csv\")\n",
    "//val productsDF: DataFrame = readCsv(TestPath + \"products.csv\")\n",
    "\n",
    "clientsDF.printSchema()\n",
    "clientsDF.show()\n",
    "//contractsDF.printSchema()\n",
    "//contractsDF.show()\n",
    "//productsDF.printSchema()\n",
    "//productsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb49e98-a62e-4324-af0b-626ec21c02ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RootPath: String = ../../resources/data/csv/\r\n",
       "moviesDf: org.apache.spark.sql.DataFrame = [movieId: string, title: string ... 1 more field]\r\n",
       "ratingsDf: org.apache.spark.sql.DataFrame = [userId: string, movieId: string ... 2 more fields]\r\n",
       "tagsDf: org.apache.spark.sql.DataFrame = [userId: string, movieId: string ... 2 more fields]\r\n",
       "schema_to_ddl: (df: org.apache.spark.sql.DataFrame)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "val RootPath = \"../../resources/data/csv/\"\n",
    "\n",
    "val moviesDf = readCsv(RootPath + \"movies.csv\")\n",
    "val ratingsDf = readCsv(RootPath + \"ratings.csv\")\n",
    "val tagsDf = readCsv(RootPath + \"tags.csv\")\n",
    "\n",
    "def schema_to_ddl(df: DataFrame): String = df.schema.toDDL.replace(\" NOT NULL\", \"\")\n",
    "\n",
    "assert(moviesDf.isInstanceOf[DataFrame] && ratingsDf.isInstanceOf[DataFrame] && tagsDf.isInstanceOf[DataFrame])\n",
    "assert (moviesDf.count() == 86537 && ratingsDf.count() == 33832162 && tagsDf.count() == 2328315)\n",
    "assert (schema_to_ddl(moviesDf) == \"movieId STRING,title STRING,genres STRING\")\n",
    "assert (schema_to_ddl(ratingsDf) == \"userId STRING,movieId STRING,rating STRING,timestamp STRING\")\n",
    "assert (schema_to_ddl(tagsDf) == \"userId STRING,movieId STRING,tag STRING,timestamp STRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7cb1f3-2308-4ea6-94da-1d61f040941b",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    Crear un método para escribir un dataframe con las siguientes caracteristicas:\n",
    "- ##### formato: parquet\n",
    "- ##### modo de escritura: overwrite\n",
    "- ##### firma: def writeParquet(df: DataFrame, path: String): Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08393772-6be3-4bc8-acea-1856800a3b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writeParquet: (df: org.apache.spark.sql.DataFrame, path: String)Unit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def writeParquet(df: DataFrame, path: String): Unit = df.write.mode(\"overwrite\").parquet(path)\n",
    "    // colocar codigo de escritura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7dcf11b-86d4-485e-bd44-204b113044e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParquetPath = ../../resources/data/parquet/\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "../../resources/data/parquet/"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Celda de prueba:\n",
    "val ParquetPath = \"../../resources/data/parquet/\"\n",
    "\n",
    "writeParquet(moviesDf, ParquetPath + \"movies\")\n",
    "writeParquet(ratingsDf, ParquetPath + \"clients\")\n",
    "writeParquet(tagsDf, ParquetPath + \"tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ee1cea1-a37e-4027-9520-abfca31b3bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_tagsDf = [userId: string, movieId: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "RootPath: String = ../../resources/data/tmp/parquet/04/\r\n",
       "_moviesDf: org.apache.spark.sql.DataFrame = [movieId: string, title: string ... 1 more field]\r\n",
       "_ratingsDf: org.apache.spark.sql.DataFrame = [userId: string, movieId: string ... 2 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[userId: string, movieId: string ... 2 more fields]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "\n",
    "val RootPath = \"../../resources/data/tmp/parquet/04/\"\n",
    "\n",
    "writeParquet(moviesDf, RootPath + \"movies\")\n",
    "writeParquet(ratingsDf, RootPath + \"ratings\")\n",
    "writeParquet(tagsDf, RootPath + \"tags\")\n",
    "\n",
    "val _moviesDf = spark.read.parquet(RootPath + \"movies\")\n",
    "val _ratingsDf = spark.read.parquet(RootPath + \"ratings\")\n",
    "val _tagsDf = spark.read.parquet(RootPath + \"tags\")\n",
    "\n",
    "assert (_moviesDf.count() == 86537)\n",
    "assert (_ratingsDf.count() == 33832162)\n",
    "assert (_tagsDf.count() == 2328315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d814457-8f21-435f-94cd-ccbc37710670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
