{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### El cliente ha pedido realizar un ajuste a las reglas implementadas hasta ahora, estos ajustes consisten en reemplazar algunas funciones hechas con groupBy por funciones Window, presta mucha atención y resuelve las siguientes actividades.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de las sesiones 06, 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b2d536-bea9-4030-ab97-ab1bc50a83a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%HTML <style>pre { white-space: pre !important; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>f}\r\n",
       "import org.apache.spark.sql.{types=>t}\r\n",
       "difference: (l1: Seq[String], l2: Seq[String])Seq[org.apache.spark.sql.Column]\r\n",
       "readTmpDf: (dfSeq: Seq[String])Map[String,org.apache.spark.sql.DataFrame]\r\n",
       "writeTmpDf: (dfSeq: Seq[(org.apache.spark.sql.DataFrame, String)])Unit\r\n",
       "schema_to_ddl: (df: org.apache.spark.sql.DataFrame)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Column, Row}\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "import org.apache.spark.sql.{types => t}\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "def difference(l1: Seq[String], l2: Seq[String]): Seq[Column] =\n",
    "    l1.diff(l2).map(colName => f.col(colName))\n",
    "\n",
    "def readTmpDf(dfSeq: Seq[String]): Map[String, DataFrame] =\n",
    "    dfSeq.map(table_name => (table_name, spark.read.parquet(\"../../resources/data/tmp/parquet/\" + table_name))).toMap\n",
    "\n",
    "def writeTmpDf(dfSeq: Seq[(DataFrame, String)]): Unit = \n",
    "    dfSeq.foreach{case (df: DataFrame, name: String) => df.write.mode(\"overwrite\").parquet(\"../../resources/data/tmp/parquet/\" + name)}\n",
    "\n",
    "def schema_to_ddl(df: DataFrame): String = df.schema.toDDL.replace(\" NOT NULL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|movie_id|title           |genres                                           |year|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|1       |Toy Story (1995)|[Adventure, Animation, Children, Comedy, Fantasy]|1995|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|               time|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|       1|   4.0|2008-11-03 11:52:19|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|   tag|               time|\n",
      "+-------+--------+------+-------------------+\n",
      "| 224183|     832|acting|2017-06-05 07:20:27|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tagsDf = [user_id: string, movie_id: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@22df8770\r\n",
       "RootPath: String = ../../resources/data/tmp/parquet/\r\n",
       "namesList: Seq[String] = List(06/movies, 06/ratings, 06/tags)\r\n",
       "dfMap: Map[String,org.apache.spark.sql.DataFrame] = Map(06/movies -> [movie_id: string, title: string ... 2 more fields], 06/ratings -> [user_id: string, movie_id: string ... 2 more fields], 06/tags -> [user_id: string, movie_id: string ... 2 more fields])\r\n",
       "moviesDf: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 2 more fields]\r\n",
       "ratingsDf: org.apache.spark.sql.DataFrame = [user_id: string, movie_id: string ... 2 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: string, movie_id: string ... 2 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "\n",
    "// Creación de sesión de Spark\n",
    "val spark = SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"ejercicio_9\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT-6\")\n",
    "\n",
    "// Carga de tablas requeridas\n",
    "val RootPath = \"../../resources/data/tmp/parquet/\"\n",
    "val namesList = Seq(\"06/movies\", \"06/ratings\", \"06/tags\")\n",
    "val dfMap = readTmpDf(namesList)\n",
    "\n",
    "val moviesDf = dfMap(\"06/movies\")\n",
    "val ratingsDf = dfMap(\"06/ratings\")\n",
    "val tagsDf = dfMap(\"06/tags\")\n",
    "\n",
    "moviesDf.show(1, false)\n",
    "ratingsDf.show(1)\n",
    "tagsDf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07f716-9806-4388-ad1a-b0fa9f4266cf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    En esta actividad hay que resolver la logica que implementaste en la \"Actividad 2 de la sesión 07 - método calculate_rating_values\" pero reemplazando el uso de la función groupBy por funciones Window. \n",
    "##### Tendrás que obtener el mismo resultado ya que en las validaciones se compararán ambos dataframes.\n",
    "##### La firma a utilizar es la siguiente:\n",
    "- ##### def calculateRatingValuesW(df: DataFrame): DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5bb862-0181-4a7e-86bd-1611fe915f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windowCRRV: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@7af82a62\r\n",
       "calculateRatingValuesW: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "import org.apache.spark.sql.expressions.{Window, WindowSpec}\n",
    "\n",
    "val windowCRRV: WindowSpec = Window.partitionBy(f.col(\"movie_id\"))\n",
    "\n",
    "def calculateRatingValuesW(df: DataFrame): DataFrame = {\n",
    "    val crv_df = df.withColumn(\"avg_rating\", f.round(f.avg(\"rating\").over(windowCRRV), 2))\n",
    "            .withColumn(\"stddev_rating\", f.round(f.stddev_pop(\"rating\").over(windowCRRV), 2))\n",
    "            .withColumn(\"count_rating\", f.count(\"rating\").over(windowCRRV))\n",
    "            .withColumn(\"min_time_rating\", f.min(\"time\").over(windowCRRV))\n",
    "            .select(\"movie_id\", \"avg_rating\", \"stddev_rating\", \"count_rating\", \"min_time_rating\")\n",
    "            .distinct() //Returns a new DataFrame containing the distinct rows in this DataFrame\n",
    "    return crv_df\n",
    "}\n",
    "    // ratingsDf modificar codigo interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f75654c-f84e-4c13-83f2-445301d53f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------+------------+-------------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|  100062|      3.63|         0.83|          64|2014-03-11 21:23:33|\n",
      "|  100070|      3.54|         0.89|          13|2013-01-24 11:24:50|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "calculateRatingValuesW(ratingsDf).show(2)\n",
    "/*\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|  100062|      3.63|         0.83|          64|2014-03-11 21:23:33|\n",
    "|  100070|      3.54|         0.89|          13|2013-01-24 11:24:50|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\"*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec544e2-6d98-427f-a16a-f74588d26ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data = [296,4.19,0.95,108756,1996-02-29 10:48:44.0]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "ratingValuesDf: org.apache.spark.sql.DataFrame = [movie_id: string, avg_rating: double ... 3 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[296,4.19,0.95,108756,1996-02-29 10:48:44.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val ratingValuesDf = calculateRatingValuesW(ratingsDf)\n",
    "\n",
    "assert(ratingValuesDf.isInstanceOf[DataFrame])\n",
    "assert(ratingValuesDf.columns.size == 5)\n",
    "assert(ratingValuesDf.count() == 83239)\n",
    "\n",
    "val data = ratingValuesDf\n",
    "    .select(f.col(\"movie_id\"),\n",
    "            f.col(\"avg_rating\").cast(t.DoubleType), \n",
    "            f.col(\"stddev_rating\").cast(t.DoubleType),\n",
    "            f.col(\"count_rating\").cast(t.LongType),\n",
    "            f.col(\"min_time_rating\").cast(t.TimestampType))\n",
    "    .filter(f.col(\"movie_id\") === \"296\")\n",
    "    .collect()(0)\n",
    "\n",
    "assert(data.getAs[String](\"movie_id\") == \"296\")\n",
    "assert(data.getAs[Double](\"avg_rating\") == 4.19)\n",
    "assert(data.getAs[Double](\"stddev_rating\") == 0.95)\n",
    "assert(data.getAs[Long](\"count_rating\") == 108756)\n",
    "assert(data.getAs[Timestamp](\"min_time_rating\") == Timestamp.valueOf(\"1996-02-29 10:48:44.0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "485c32fa-def0-4176-8d5e-50cf3358a8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfs = List(([movie_id: string, avg_rating: double ... 3 more fields],09/ratings))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List(([movie_id: string, avg_rating: double ... 3 more fields],09/ratings))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((ratingValuesDf, \"09/ratings\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7f23a-b777-44d4-ae7e-fe6308e6a8c1",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    En esta actividad hay que resolver la logica que implementaste en la \"Actividad 3 de la sesión 07 - métodos getAct3Df1 y getAct3Df2\" pero reemplazando el uso de la función groupBy por funciones Window. \n",
    "##### Tendrás que obtener el mismo resultado ya que en las validaciones se compararán ambos dataframes.\n",
    "##### La firma a utilizar es la siguiente:\n",
    "- ##### Primer tabla (utilizando función concat_ws o concat): def getAct3Df1W(df: DataFrame) -> DataFrame:\n",
    "- ##### Segunda tabla (utilizando función struct): def getAct3Df2W(df: DataFrame) -> DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef908315-d821-4c3a-9c11-1e0d675c5d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "windowGA32 = org.apache.spark.sql.expressions.WindowSpec@1b627ea7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "windowGA31: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@73aa1495\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.expressions.WindowSpec@1b627ea7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Declaración de windows:\n",
    "val windowGA31: WindowSpec = Window.partitionBy(f.col(\"movie_id\"), f.col(\"tag\")) //aquí antes tenía un f.upper(f.col(\"tag\")) pero no transformaba\n",
    "val windowGA32: WindowSpec = Window.partitionBy(f.col(\"movie_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c013c1e-f140-45b1-ba93-336aef9acedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getAct3Df1W: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\r\n",
       "getAct3Df2W: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA, PUEDES GENERAR MÉTODOS O VARIABLES NUEVAS SI ASI LO REQUIERES\n",
    "\n",
    "def getAct3Df1W(df: DataFrame): DataFrame = {\n",
    "    val dfMTTw = df\n",
    "        .withColumn(\"tag_count\", f.concat_ws(\" : \", f.upper(f.col(\"tag\")), f.count(\"tag\").over(windowGA31)))\n",
    "        .withColumn(\"min_tag\", f.min(\"time\").over(windowGA31))\n",
    "        .select(\"movie_id\", \"tag_count\", \"min_tag\")\n",
    "        .distinct()\n",
    "    val tabla1DFFw = dfMTTw\n",
    "        .withColumn(\"tag_count\", f.sort_array(f.collect_set(\"tag_count\").over(windowGA32)))\n",
    "        .withColumn(\"min_time_tag\", f.min(\"min_tag\").over(windowGA32))\n",
    "        .select(\"movie_id\", \"tag_count\", \"min_time_tag\")\n",
    "        .distinct()\n",
    "    return tabla1DFFw\n",
    "}\n",
    "    // ... transformaciones a tagsDf\n",
    "\n",
    "def getAct3Df2W(df: DataFrame): DataFrame = {\n",
    "    val dfMTTw2 = df\n",
    "        .withColumn(\"tag\", f.upper(f.col(\"tag\")))\n",
    "        .withColumn(\"count\", f.count(\"tag\").over(windowGA31))\n",
    "        .withColumn(\"struct\", f.struct(f.col(\"tag\"), f.col(\"count\")))\n",
    "        .withColumn(\"min_tag\", f.min(\"time\").over(windowGA31))\n",
    "        .select(\"movie_id\", \"struct\", \"min_tag\")\n",
    "        .distinct()\n",
    "    val tabla2DFFw = dfMTTw2\n",
    "        .withColumn(\"tag_count\", f.sort_array(f.collect_set(\"struct\").over(windowGA32)))\n",
    "        .withColumn(\"min_time_tag\", f.min(\"min_tag\").over(windowGA32))\n",
    "        .select(\"movie_id\", \"tag_count\", \"min_time_tag\")\n",
    "        .distinct()\n",
    "    return tabla2DFFw\n",
    "}\n",
    "    // ... transformaciones a tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b76900e-7ba9-4d99-bb20-2540cca7d4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                         |min_time_tag       |\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
      "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                             |min_time_tag       |\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
      "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "act3Df1: org.apache.spark.sql.DataFrame = [movie_id: string, tag_count: array<string> ... 1 more field]\r\n",
       "act3Df2: org.apache.spark.sql.DataFrame = [movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 1 more field]\r\n",
       "\"\r\n",
       "Ejemplo de salida esperada:\r\n",
       "+--------+------------------------------------------------------------------+-------------------+\r\n",
       "movie_id|tag_count                                                         |min_time_tag       |\r\n",
       "+--------+------------------------------------------------------------------+-------------------+\r\n",
       "100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\r\n",
       "100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\r\n",
       "+--------+------------...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val act3Df1 = getAct3Df1W(tagsDf)\n",
    "val act3Df2 = getAct3Df2W(tagsDf)\n",
    "\n",
    "act3Df1.show(2, false)\n",
    "act3Df2.show(2, false)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                         |min_time_tag       |\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
    "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                             |min_time_tag       |\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
    "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "229650b4-a2d1-4c52-82e5-576defdfbb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schemaDf2 = StructType(StructField(movie_id,StringType,true),StructField(tag_count,ArrayType(StructType(Struc...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\r\n",
       "expectedValueDf1: Seq[org.apache.spark.sql.Row] = List([100070,List(COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1),2017-05-19 17:17:36.0])\r\n",
       "schemaDf1: org.apache.spark.sql.types.StructType = StructType(StructField(movie_id,StringType,true),StructField(tag_count,ArrayType(StringType,true),true),StructField(min_time_tag,StringType,true))\r\n",
       "testDf1: org.apache.spark.sql.DataFrame = [movie_id: string, tag_count: array<string> ... 1 more field]\r\n",
       "expectedValueDf2: Seq[org.apache.spark.sql.Row] = List([100070,List([COMEDIAN,2], [COMEDY,1], [GOOD HUMOUR,1], [STRUGGLING CAREER,1]),2017-05-19 17:17:36.0])\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(movie_id,StringType,true),StructField(tag_count,ArrayType(StructType(Struc..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val expectedValueDf1 = Seq(Row(\"100070\",\n",
    "                               List(\"COMEDIAN : 2\",\n",
    "                                    \"COMEDY : 1\",\n",
    "                                    \"GOOD HUMOUR : 1\",\n",
    "                                    \"STRUGGLING CAREER : 1\"),\n",
    "                                   (\"2017-05-19 17:17:36.0\")))\n",
    "val schemaDf1 = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"min_time_tag\", t.StringType)\n",
    "))\n",
    "assert(act3Df1.columns.size == 3)\n",
    "assert(act3Df1.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(act3Df1.columns.toSeq.contains(\"tag_count\"))\n",
    "assert(act3Df1.columns.toSeq.contains(\"min_time_tag\"))\n",
    "assert(schema_to_ddl(act3Df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == \"movie_id STRING,tag_count ARRAY<STRING>,min_time_tag TIMESTAMP\")\n",
    "assert(act3Df1.count() == 53452)\n",
    "val testDf1 = spark.createDataFrame(spark.sparkContext.parallelize(expectedValueDf1), schemaDf1)\n",
    "    .withColumn(\"min_time_tag\", f.col(\"min_time_tag\").cast(t.TimestampType))\n",
    "assert(act3Df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\").filter(f.col(\"movie_id\") === \"100070\").except(testDf1).count() == 0)\n",
    "\n",
    "val expectedValueDf2 = Seq(Row(\"100070\",\n",
    "                               List(Row(\"COMEDIAN\",2L),\n",
    "                                    Row(\"COMEDY\",1L),\n",
    "                                    Row(\"GOOD HUMOUR\",1L),\n",
    "                                    Row(\"STRUGGLING CAREER\",1L)),\n",
    "                                   (\"2017-05-19 17:17:36.0\")))\n",
    "val schemaDf2 = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.StringType)\n",
    "))\n",
    "assert(act3Df2.columns.size == 3)\n",
    "assert(act3Df2.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(act3Df2.columns.toSeq.contains(\"tag_count\"))\n",
    "assert(act3Df2.columns.toSeq.contains(\"min_time_tag\"))\n",
    "assert(schema_to_ddl(act3Df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == \"movie_id STRING,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,min_time_tag TIMESTAMP\")\n",
    "assert(act3Df2.count() == 53452)\n",
    "val testDf2 = spark.createDataFrame(spark.sparkContext.parallelize(expectedValueDf2), schemaDf2)\n",
    "    .withColumn(\"min_time_tag\", f.col(\"min_time_tag\").cast(t.TimestampType))\n",
    "assert(act3Df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\").filter(f.col(\"movie_id\") === \"100070\").except(testDf2).count() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5328bd3f-1e6b-4ab7-950c-22e4904f07cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfs = List(([movie_id: string, tag_count: array<string> ... 1 more field],09/tags_p1), ([movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 1 more field],09/tags_p2))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List(([movie_id: string, tag_count: array<string> ... 1 more field],09/tags_p1), ([movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 1 more field],09/tags_p2))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((act3Df1, \"09/tags_p1\"),\n",
    "              (act3Df2, \"09/tags_p2\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81bf84ab-0b94-4dc6-829e-b683e337b304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastMoviesDf = [movie_id: string, title: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 8 more fields]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val lastMoviesDf = moviesDf\n",
    "    .join(act3Df2, Seq(\"movie_id\"), \"left\")\n",
    "    .join(ratingValuesDf, Seq(\"movie_id\"), \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea21abfb-d225-4147-8a5f-7aad1afbbfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfs = List(([movie_id: string, title: string ... 8 more fields],09/movies))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List(([movie_id: string, title: string ... 8 more fields],09/movies))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((lastMoviesDf, \"09/movies\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7747f5-bf41-4a4d-a775-90cc9c75455a",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    La última actividad a realizar es la siguiente:\n",
    "- ##### El cliente nos ha solicitado generar una tabla donde se muestre el top de peliculas ranqueadas por genero, para realizar esto se realizan los siguientes pasos:\n",
    "    - ##### Las peliculas que entran a la parte del ranqueo deben cumplir con las siguientes condiciones:\n",
    "        -  count_rating > 1000\n",
    "        -  avg_rating >= 4.2\n",
    "        -  stddev_rating < 2\n",
    "    - #####  Descomponer la columna \"genres\" en una columna llamada \"genre\"\n",
    "    - ##### Agregar la columna \"top\" donde se asignará el valor de la función \"rank\" de Spark tomando las siguientes caracteristicas:\n",
    "        - particionar por: \"genre\"\n",
    "        - order por: avg_rating DESC, stddev_rating ASC, count_rating DESC\n",
    "##### El esquema resultante deberá ser:\n",
    "* |-- title: string\n",
    "* |-- year: integer\n",
    "* |-- genre: string\n",
    "* |-- top: integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d21f3657-54ba-4b2a-a139-1ba41daa8b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topMoviesDf = [title: string, year: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "dfAct3: org.apache.spark.sql.DataFrame = [title: string, year: int ... 4 more fields]\r\n",
       "windowAct3: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@55d311c9\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[title: string, year: int ... 2 more fields]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "//val topMoviesDf = lastMoviesDf // Transformaciones a lastMoviesDf\n",
    "\n",
    "val dfAct3 = lastMoviesDf\n",
    "    .filter(\n",
    "        (f.col(\"count_rating\") > 1000) &&\n",
    "        (f.col(\"avg_rating\") >= 4.2) &&\n",
    "        (f.col(\"stddev_rating\") < 2)\n",
    "    )\n",
    "    .select(\n",
    "        f.col(\"title\"),\n",
    "        f.col(\"year\"),\n",
    "        f.col(\"avg_rating\"),\n",
    "        f.col(\"stddev_rating\"),\n",
    "        f.col(\"count_rating\"),\n",
    "        f.explode(f.col(\"genres\")).alias(\"genre\")\n",
    "    )\n",
    "\n",
    "// TEST\n",
    "// df_act3.show(5)\n",
    "\n",
    "val windowAct3: WindowSpec = Window\n",
    "    .partitionBy(f.col(\"genre\"))\n",
    "    .orderBy(\n",
    "        f.col(\"avg_rating\").desc,\n",
    "        f.col(\"stddev_rating\").asc,\n",
    "        f.col(\"count_rating\").desc\n",
    "    )\n",
    "\n",
    "val topMoviesDf = dfAct3\n",
    "    .withColumn(\"top\", f.rank().over(windowAct3))\n",
    "    .select(\"title\", \"year\", \"genre\", \"top\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a250478e-7fff-4384-bbbf-9ae81599285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+---+\n",
      "|               title|year|    genre|top|\n",
      "+--------------------+----+---------+---+\n",
      "|Band of Brothers ...|2001|   Action|  1|\n",
      "|Seven Samurai (Sh...|1954|   Action|  2|\n",
      "|   Fight Club (1999)|1999|   Action|  3|\n",
      "|Over the Garden W...|2013|Adventure|  1|\n",
      "|Seven Samurai (Sh...|1954|Adventure|  2|\n",
      "+--------------------+----+---------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\r\n",
       "Ejemplo de salida esperada (hay que mantener mismo orden de columnas):\r\n",
       "+--------------------+----+---------+---+\r\n",
       "               title|year|    genre|top|\r\n",
       "+--------------------+----+---------+---+\r\n",
       "Band of Brothers ...|2001|   Action|  1|\r\n",
       "Seven Samurai (Sh...|1954|   Action|  2|\r\n",
       "   Fight Club (1999)|1999|   Action|  3|\r\n",
       "Over the Garden W...|2013|Adventure|  1|\r\n",
       "Seven Samurai (Sh...|1954|Adventure|  2|\r\n",
       "+--------------------+----+---------+---+\r\n",
       "only showing top 5 rows\r\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "topMoviesDf.show(5)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (hay que mantener mismo orden de columnas):\n",
    "+--------------------+----+---------+---+\n",
    "|               title|year|    genre|top|\n",
    "+--------------------+----+---------+---+\n",
    "|Band of Brothers ...|2001|   Action|  1|\n",
    "|Seven Samurai (Sh...|1954|   Action|  2|\n",
    "|   Fight Club (1999)|1999|   Action|  3|\n",
    "|Over the Garden W...|2013|Adventure|  1|\n",
    "|Seven Samurai (Sh...|1954|Adventure|  2|\n",
    "+--------------------+----+---------+---+\n",
    "only showing top 5 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e8d5a52-1f1a-4ade-ba04-41266a276ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedTopMovies = List([Band of Brothers (2001),2001,Action,1], [Seven Samurai (Shichinin no samurai) (1954),1954,Action,2], [Fight Club (1999),1999,Action,3], [Over the Garden Wall (2013),2013,Adventure,1], [Seven Samurai (Shichinin no samurai) (1954),1954,Adventure,2], [Spirited Away (Sen to Chihiro no kamikakushi) (2001),2001,Adventure,3], [Over the Garden Wall (2013),2013,Animation,1], [Spirited Away (Sen to Chihiro no kamikakushi) (2001),2001,Animation,2], [Parasite (2019),2019,Comedy,1], [Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964),1964,Comedy,2], [Shawshank Redemption, The (1994),1994,Crime,1], [Godfather, The (1972),1972,Crime,2], [Usual Suspects, The (1995),1995,Crime,3], [Godfather: Part II, The (1974),1974,Crime...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List([Band of Brothers (2001),2001,Action,1], [Seven Samurai (Shichinin no samurai) (1954),1954,Action,2], [Fight Club (1999),1999,Action,3], [Over the Garden Wall (2013),2013,Adventure,1], [Seven Samurai (Shichinin no samurai) (1954),1954,Adventure,2], [Spirited Away (Sen to Chihiro no kamikakushi) (2001),2001,Adventure,3], [Over the Garden Wall (2013),2013,Animation,1], [Spirited Away (Sen to Chihiro no kamikakushi) (2001),2001,Animation,2], [Parasite (2019),2019,Comedy,1], [Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964),1964,Comedy,2], [Shawshank Redemption, The (1994),1994,Crime,1], [Godfather, The (1972),1972,Crime,2], [Usual Suspects, The (1995),1995,Crime,3], [Godfather: Part II, The (1974),1974,Crime..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "val expectedTopMovies = Seq(\n",
    "    Row(\"Band of Brothers (2001)\", 2001, \"Action\", 1),\n",
    "    Row(\"Seven Samurai (Shichinin no samurai) (1954)\", 1954, \"Action\", 2),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Action\", 3),\n",
    "    Row(\"Over the Garden Wall (2013)\", 2013, \"Adventure\", 1),\n",
    "    Row(\"Seven Samurai (Shichinin no samurai) (1954)\", 1954, \"Adventure\", 2),\n",
    "    Row(\"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\", 2001, \"Adventure\", 3),\n",
    "    Row(\"Over the Garden Wall (2013)\", 2013, \"Animation\", 1),\n",
    "    Row(\"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\", 2001, \"Animation\", 2),\n",
    "    Row(\"Parasite (2019)\", 2019, \"Comedy\", 1),\n",
    "    Row(\"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\", 1964, \"Comedy\", 2),\n",
    "    Row(\"Shawshank Redemption, The (1994)\", 1994, \"Crime\", 1),\n",
    "    Row(\"Godfather, The (1972)\", 1972, \"Crime\", 2),\n",
    "    Row(\"Usual Suspects, The (1995)\", 1995, \"Crime\", 3),\n",
    "    Row(\"Godfather: Part II, The (1974)\", 1974, \"Crime\", 4),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Crime\", 5),\n",
    "    Row(\"Planet Earth (2006)\", 2006, \"Documentary\", 1),\n",
    "    Row(\"Planet Earth II (2016)\", 2016, \"Documentary\", 2),\n",
    "    Row(\"Blue Planet II (2017)\", 2017, \"Documentary\", 3),\n",
    "    Row(\"The Blue Planet (2001)\", 2001, \"Documentary\", 4),\n",
    "    Row(\"Shawshank Redemption, The (1994)\", 1994, \"Drama\", 1),\n",
    "    Row(\"Band of Brothers (2001)\", 2001, \"Drama\", 2),\n",
    "    Row(\"Parasite (2019)\", 2019, \"Drama\", 3),\n",
    "    Row(\"Godfather, The (1972)\", 1972, \"Drama\", 4),\n",
    "    Row(\"Twin Peaks (1989)\", 1989, \"Drama\", 5),\n",
    "    Row(\"12 Angry Men (1957)\", 1957, \"Drama\", 6),\n",
    "    Row(\"Godfather: Part II, The (1974)\", 1974, \"Drama\", 7),\n",
    "    Row(\"Over the Garden Wall (2013)\", 2013, \"Drama\", 8),\n",
    "    Row(\"Seven Samurai (Shichinin no samurai) (1954)\", 1954, \"Drama\", 9),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Drama\", 10),\n",
    "    Row(\"Schindler's List (1993)\", 1993, \"Drama\", 11),\n",
    "    Row(\"One Flew Over the Cuckoo's Nest (1975)\", 1975, \"Drama\", 12),\n",
    "    Row(\"Lives of Others, The (Das leben der Anderen) (2006)\", 2006, \"Drama\", 13),\n",
    "    Row(\"Casablanca (1942)\", 1942, \"Drama\", 14),\n",
    "    Row(\"Spirited Away (Sen to Chihiro no kamikakushi) (2001)\", 2001, \"Fantasy\", 1),\n",
    "    Row(\"Twin Peaks (1989)\", 1989, \"Mystery\", 1),\n",
    "    Row(\"Usual Suspects, The (1995)\", 1995, \"Mystery\", 2),\n",
    "    Row(\"Rear Window (1954)\", 1954, \"Mystery\", 3),\n",
    "    Row(\"Lives of Others, The (Das leben der Anderen) (2006)\", 2006, \"Romance\", 1),\n",
    "    Row(\"Casablanca (1942)\", 1942, \"Romance\", 2),\n",
    "    Row(\"Usual Suspects, The (1995)\", 1995, \"Thriller\", 1),\n",
    "    Row(\"Fight Club (1999)\", 1999, \"Thriller\", 2),\n",
    "    Row(\"Rear Window (1954)\", 1954, \"Thriller\", 3),\n",
    "    Row(\"Lives of Others, The (Das leben der Anderen) (2006)\", 2006, \"Thriller\", 4),\n",
    "    Row(\"Band of Brothers (2001)\", 2001, \"War\", 1),\n",
    "    Row(\"Schindler's List (1993)\", 1993, \"War\", 2),\n",
    "    Row(\"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\", 1964, \"War\", 3)\n",
    ")\n",
    "\n",
    "topMoviesDf\n",
    "    .select(f.col(\"title\"),f.col(\"year\").cast(t.IntegerType),f.col(\"genre\"),f.col(\"top\").cast(t.IntegerType))\n",
    "    .orderBy(f.col(\"genre\").asc, f.col(\"top\").asc)\n",
    "    .collect()\n",
    "    .zip(expectedTopMovies)\n",
    "    .foreach(tuple => {\n",
    "        assert(tuple._1.getAs[String](\"title\") == tuple._2.getAs[String](0))\n",
    "        assert(tuple._1.getAs[Int](\"year\") == tuple._2.getAs[Int](1))\n",
    "        assert(tuple._1.getAs[String](\"genre\") == tuple._2.getAs[String](2))\n",
    "        assert(tuple._1.getAs[Int](\"top\") == tuple._2.getAs[Int](3))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ea6c8bf-1fc0-40f7-8d4d-9711e0ec36a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfs = List(([title: string, year: int ... 2 more fields],09/top_movies))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List(([title: string, year: int ... 2 more fields],09/top_movies))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((topMoviesDf, \"09/top_movies\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69335a59-913c-4eaa-82a3-a9668a64c9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
