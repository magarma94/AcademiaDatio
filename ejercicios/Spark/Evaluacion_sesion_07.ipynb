{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### El cliente nos ha solicitado realizar algunos métodos que resuelvan consultas específicas sobre las tablas movies_df, ratings_df y tags_df. Lee cuidadosamente cada consulta y desarrolla el método correspondiente dada la firma del método requerida.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de la sesión 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d2ac7f-a13f-495e-85d4-29efca6bfdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%HTML <style>pre { white-space: pre !important; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>f}\r\n",
       "import org.apache.spark.sql.{types=>t}\r\n",
       "difference: (l1: Seq[String], l2: Seq[String])Seq[org.apache.spark.sql.Column]\r\n",
       "readTmpDf: (dfSeq: Seq[String])Map[String,org.apache.spark.sql.DataFrame]\r\n",
       "writeTmpDf: (dfSeq: Seq[(org.apache.spark.sql.DataFrame, String)])Unit\r\n",
       "schema_to_ddl: (df: org.apache.spark.sql.DataFrame)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Column, Row}\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "import org.apache.spark.sql.{types => t}\n",
    "\n",
    "def difference(l1: Seq[String], l2: Seq[String]): Seq[Column] =\n",
    "    l1.diff(l2).map(colName => f.col(colName))\n",
    "\n",
    "def readTmpDf(dfSeq: Seq[String]): Map[String, DataFrame] =\n",
    "    dfSeq.map(table_name => (table_name, spark.read.parquet(\"../../resources/data/tmp/parquet/\" + table_name))).toMap\n",
    "\n",
    "def writeTmpDf(dfSeq: Seq[(DataFrame, String)]): Unit = \n",
    "    dfSeq.foreach{case (df: DataFrame, name: String) => df.write.mode(\"overwrite\").parquet(\"../../resources/data/tmp/parquet/\" + name)}\n",
    "\n",
    "def schema_to_ddl(df: DataFrame): String = df.schema.toDDL.replace(\" NOT NULL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|movie_id|title           |genres                                           |year|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|1       |Toy Story (1995)|[Adventure, Animation, Children, Comedy, Fantasy]|1995|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|               time|\n",
      "+-------+--------+------+-------------------+\n",
      "|      1|       1|   4.0|2008-11-03 11:52:19|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|   tag|               time|\n",
      "+-------+--------+------+-------------------+\n",
      "| 224183|     832|acting|2017-06-05 07:20:27|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tagsDf = [user_id: string, movie_id: string ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@725ac73b\r\n",
       "RootPath: String = ../../resources/data/tmp/parquet/\r\n",
       "namesList: Seq[String] = List(06/movies, 06/ratings, 06/tags)\r\n",
       "dfMap: Map[String,org.apache.spark.sql.DataFrame] = Map(06/movies -> [movie_id: string, title: string ... 2 more fields], 06/ratings -> [user_id: string, movie_id: string ... 2 more fields], 06/tags -> [user_id: string, movie_id: string ... 2 more fields])\r\n",
       "moviesDf: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 2 more fields]\r\n",
       "ratingsDf: org.apache.spark.sql.DataFrame = [user_id: string, movie_id: string ... 2 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[user_id: string, movie_id: string ... 2 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "\n",
    "// Creación de sesión de Spark\n",
    "val spark = SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"ejercicio_7\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT-6\")\n",
    "\n",
    "// Carga de tablas requeridas\n",
    "val RootPath = \"../../resources/data/tmp/parquet/\"\n",
    "val namesList = Seq(\"06/movies\", \"06/ratings\", \"06/tags\")\n",
    "val dfMap = readTmpDf(namesList)\n",
    "\n",
    "val moviesDf = dfMap(\"06/movies\")\n",
    "val ratingsDf = dfMap(\"06/ratings\")\n",
    "val tagsDf = dfMap(\"06/tags\")\n",
    "\n",
    "moviesDf.show(1, false)\n",
    "ratingsDf.show(1)\n",
    "tagsDf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c8e25-807a-4e35-b763-57dcab283721",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    Para el dataframe \"moviesDf\":\n",
    "- ##### Genera un método llamado getAllGenres que retorne un DataFrame con únicamente una columna conteniendo todos los valores distintos (sin repetir) de la columna \"genres\"\n",
    "    - ##### Firma: def getAllGenres(df: DataFrame): DataFrame\n",
    "    - Apoyate de la funcion explode -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode.html#pyspark.sql.functions.explode\n",
    "\n",
    "- ##### Genera un método llamado get_min_year que retorne un valor de tipo int que contenga el menor año registrado (omitiendo nulls)\n",
    "    - ##### Firma: def getMinYear(df: DataFrame): Int\n",
    "    - ##### Necesitarás llamar alguna de las siguientes acciones: take, first, head.\n",
    "\n",
    "- ##### Genera un método llamado get_min_year que retorne un valor de tipo int que contenga el mayor año registrado (omitiendo nulls)\n",
    "    - ##### Firma: def getMaxYear(df: DataFrame): Int\n",
    "    - ##### Necesitarás llamar alguna de las siguientes acciones: take, first, head.\n",
    "\n",
    "##### NO UTILIZAR withColumn NI withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fabb9fe-b06e-49f5-a09a-15f23a97a6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|movie_id|title           |genres                                           |year|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|1       |Toy Story (1995)|[Adventure, Animation, Children, Comedy, Fantasy]|1995|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesDf.show(1, false)\n",
    "moviesDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ef84506-2869-4e5d-9d5e-3104a30f29f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getAllGenres: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\r\n",
       "getMinYear: (df: org.apache.spark.sql.DataFrame)Int\r\n",
       "getMaxYear: (df: org.apache.spark.sql.DataFrame)Int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def getAllGenres(df: DataFrame): DataFrame = {\n",
    "    val gagDf = df\n",
    "        .select(\n",
    "            f.explode(f.col(\"genres\")).alias(\"list_of_genres\")\n",
    "        )\n",
    "        .distinct()\n",
    "    return gagDf\n",
    "}\n",
    "    \n",
    "def getMinYear(df: DataFrame): Int = {\n",
    "    val gminyDf = df\n",
    "        .groupBy(f.col(\"year\"))\n",
    "        .agg(\n",
    "            f.count(\"*\").alias(\"count\")\n",
    "        )\n",
    "        .orderBy(f.col(\"year\").asc, f.col(\"count\").asc)\n",
    "        .filter(f.col(\"year\").isNotNull)\n",
    "    return gminyDf.select(\"year\").first.getAs[Int](\"year\")\n",
    "}\n",
    "    \n",
    "def getMaxYear(df: DataFrame): Int = {\n",
    "    val gmaxDf = df\n",
    "        .groupBy(f.col(\"year\"))\n",
    "        .agg(\n",
    "            f.count(\"*\").alias(\"count\")\n",
    "        )\n",
    "        .orderBy(f.col(\"year\").desc, f.col(\"count\").desc)\n",
    "        .filter(f.col(\"year\").isNotNull)\n",
    "    return gmaxDf.select(\"year\").first.getAs[Int](\"year\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "68252b23-7945-4b65-9994-20980eb23889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|list_of_genres|\n",
      "+--------------+\n",
      "|Crime         |\n",
      "|Romance       |\n",
      "|Thriller      |\n",
      "|Adventure     |\n",
      "|Drama         |\n",
      "|War           |\n",
      "|Documentary   |\n",
      "|Fantasy       |\n",
      "|Mystery       |\n",
      "|Musical       |\n",
      "|Animation     |\n",
      "|Film-Noir     |\n",
      "|IMAX          |\n",
      "|Horror        |\n",
      "|Western       |\n",
      "|Comedy        |\n",
      "|Children      |\n",
      "|Action        |\n",
      "|Sci-Fi        |\n",
      "+--------------+\n",
      "\n",
      "1874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<console>:33: warning: a pure expression does nothing in statement position; multiline expressions may require enclosing parentheses\r\n",
       "       \"\"\"\r\n",
       "       ^\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023\n"
     ]
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "getAllGenres(moviesDf).show(20, false)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (el nombre de la columna podría ser distinto):\n",
    "+-----------+\n",
    "|col        |\n",
    "+-----------+\n",
    "|Crime      |\n",
    "|Romance    |\n",
    "|Thriller   |\n",
    "|Adventure  |\n",
    "|Drama      |\n",
    "|War        |\n",
    "|Documentary|\n",
    "|Fantasy    |\n",
    "|Mystery    |\n",
    "|Musical    |\n",
    "|Animation  |\n",
    "|Film-Noir  |\n",
    "|IMAX       |\n",
    "|Horror     |\n",
    "|Western    |\n",
    "|Comedy     |\n",
    "|Children   |\n",
    "|Action     |\n",
    "|Sci-Fi     |\n",
    "+-----------+\n",
    "\"\"\"\n",
    "println(getMinYear(moviesDf))\n",
    "// Salida esperada: 1874\n",
    "println(getMaxYear(moviesDf))\n",
    "// Salida esperada: 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cdfe845e-3491-4366-8759-49d8eae1b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxYear = 2023\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "genresDf: org.apache.spark.sql.DataFrame = [list_of_genres: string]\r\n",
       "expectedOutput: Seq[String] = List(Action, Adventure, Animation, Children, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, IMAX, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western)\r\n",
       "genresList: Array[String] = Array(Action, Adventure, Animation, Children, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, IMAX, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western)\r\n",
       "minYear: Int = 1874\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "val genresDf = getAllGenres(moviesDf)\n",
    "\n",
    "assert(genresDf.isInstanceOf[DataFrame])\n",
    "assert(genresDf.columns.size == 1)\n",
    "\n",
    "val expectedOutput = Seq(\"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\", \n",
    "                         \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \n",
    "                         \"Horror\", \"IMAX\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \n",
    "                         \"Thriller\", \"War\", \"Western\")\n",
    "val genresList = genresDf.rdd.map(item => item(0).toString).collect().sortWith(_.compareTo(_) < 0)\n",
    "assert(genresList.diff(expectedOutput).size + expectedOutput.diff(genresList).size == 0)\n",
    "\n",
    "val minYear = getMinYear(moviesDf)\n",
    "assert(minYear == 1874)\n",
    "\n",
    "val maxYear = getMaxYear(moviesDf)\n",
    "assert(maxYear == 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1377e4-71a4-4479-bc6c-a7b6288164d0",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO -> Para la tabla \"ratingsDf\" el cliente requiere hacer un análisis de cada \"movie_id\" para tener una idea de qué tan buena es cada pelicula, asi que nos solicitó desarrollar un método que realice múltiples cálculos.\n",
    "##### Generar un método que retorne un DataFrame con las columnas especificadas por cada \"movie_id\":\n",
    "- ##### Firma: def calculateRatingValues(df: DataFrame): DataFrame\n",
    "- ##### Columnas generadas:\n",
    "    - ##### nombre: avg_rating, tipo: DoubleType() -> Valor rating promedio (Redondear a 2 decimales)\n",
    "    - ##### nombre: stddev_rating, tipo: DoubleType() -> Desviacion estándar (stddev_pop) para la columna rating (Redondear a 2 decimales)\n",
    "        - Para redondear valores utiliza la función round de Spark -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.round.html#pyspark.sql.functions.round\n",
    "    - ##### nombre: count_rating, tipo: LongType() -> Total de calificaciones recibidas\n",
    "- ##### ACTUALIZACIÓN: Para aquellas peliculas (movie_id) que no se tenga identificado su año en la tabla \"movies_df\" nos han solicitado calcular el año de la siguiente manera (más adelante nos preocuparemos por pegar el año a la tabla movies_df):\n",
    "    - ##### nombre: min_time_rating, tipo: TimestampType() -> Fecha más antigua de la columna \"time\" en la que se asignó el primer rating\n",
    "##### Nota 1: podemos hacer el calculo de \"min_time_rating\" en la misma transformación en las que se generan las columnas \"avg_rating\", \"stddev_rating\", y \"count_rating\"\n",
    "##### Nota 2: Posiblemente requieras analizar las funciones de agregación existentes en Spark -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html#aggregate-functions\n",
    "* El dataframe de salida deberá contar con la siguiente estructura al hacer printSchema():\n",
    "* |-- movie_id: string\n",
    "* |-- avg_rating: double\n",
    "* |-- stddev_rating: double\n",
    "* |-- count_rating: long\n",
    "* |-- min_time_rating: timestamp\n",
    "##### NO UTILIZAR withColumn NI withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9fb66264-795f-4121-96b6-b710d490adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+-------------------+\n",
      "|user_id|movie_id|rating|time               |\n",
      "+-------+--------+------+-------------------+\n",
      "|1      |1       |4.0   |2008-11-03 11:52:19|\n",
      "|1      |110     |4.0   |2008-11-05 00:04:46|\n",
      "|1      |158     |4.0   |2008-11-03 11:31:43|\n",
      "|1      |260     |4.5   |2008-11-03 12:00:04|\n",
      "|1      |356     |5.0   |2008-11-03 11:58:39|\n",
      "+-------+--------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsDf.show(5,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8050433f-5e9d-459f-baa5-eb289a05f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculateRatingValues: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def calculateRatingValues(df: DataFrame): DataFrame = {\n",
    "    val crvRatingsDf = df\n",
    "    .groupBy(f.col(\"movie_id\"))\n",
    "    .agg(\n",
    "        f.round(f.avg(\"rating\"),2).alias(\"avg_rating\"),\n",
    "        f.round(f.stddev(\"rating\"),2).alias(\"stddev_rating\"),\n",
    "        f.count(\"rating\").alias(\"count_rating\"),\n",
    "        f.min(\"time\").alias(\"min_time_rating\")\n",
    "    )\n",
    "    return crvRatingsDf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ffac13b5-d99c-468b-80ce-908808d21a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------+------------+-------------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|     296|      4.19|         0.95|      108756|1996-02-29 10:48:44|\n",
      "|  115713|      3.99|         0.83|       21335|2015-01-02 06:05:51|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\r\n",
       "Ejemplo de salida esperada:\r\n",
       "+--------+----------+-------------+------------+-------------------+\r\n",
       "movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\r\n",
       "+--------+----------+-------------+------------+-------------------+\r\n",
       "     296|      4.19|         0.95|      108756|1996-02-29 10:48:44|\r\n",
       "  115713|      3.99|         0.83|       21335|2015-01-02 06:05:51|\r\n",
       "+--------+----------+-------------+------------+-------------------+\r\n",
       "only showing top 2 rows\r\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "calculateRatingValues(ratingsDf).show(2)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "|     296|      4.19|         0.95|      108756|1996-02-29 10:48:44|\n",
    "|  115713|      3.99|         0.83|       21335|2015-01-02 06:05:51|\n",
    "+--------+----------+-------------+------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66937ba3-9f1a-42b2-801f-4b5daf250796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "testDf = [movie_id: string, avg_rating: double ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "ratingValuesDf: org.apache.spark.sql.DataFrame = [movie_id: string, avg_rating: double ... 3 more fields]\r\n",
       "data: Seq[org.apache.spark.sql.Row] = List([296,4.19,0.95,108756,1996-02-29 10:48:44.0])\r\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(movie_id,StringType,true),StructField(avg_rating,DoubleType,true),StructField(stddev_rating,DoubleType,true),StructField(count_rating,LongType,true),StructField(min_time_rating,TimestampType,true))\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, avg_rating: double ... 3 more fields]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val ratingValuesDf = calculateRatingValues(ratingsDf)\n",
    "\n",
    "assert(ratingValuesDf.isInstanceOf[DataFrame])\n",
    "assert(ratingValuesDf.columns.size == 5)\n",
    "assert(ratingValuesDf.count() == 83239)\n",
    "\n",
    "val data = Seq(Row(\"296\", 4.19, 0.95, 108756L, Timestamp.valueOf(\"1996-02-29 10:48:44.0\")))\n",
    "\n",
    "val schema = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType),\n",
    "    t.StructField(\"count_rating\", t.LongType),\n",
    "    t.StructField(\"min_time_rating\", t.TimestampType)))\n",
    "\n",
    "val testDf = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n",
    "assert(ratingValuesDf.filter(f.col(\"movie_id\") === \"296\").except(testDf).count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04fba01-1cfc-4cad-906c-760eb205745d",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO -> El cliente ha solicitado generar dos tablas con el mismo contenido pero con distinto esquema a partir de la tabla \"tagsDf\", lee a continuación la información enviada con los requerimientos:\n",
    "- ##### En ambas tablas se requiere agrupar por \"movie_id\" y calcular:\n",
    "    - ##### El total de veces en las que aparece cada tag (en mayusculas) .\n",
    "    - ##### Fecha más antigua en la que se asignó el primer tag.\n",
    "La primer tabla deberá tener la siguiente estructura:  \n",
    "*      | movie_id |             tag_count |        min_time_tag |\n",
    "*      |        1 | [SCI-FI:2, TERROR:12] | 2017-06-02 07:20:27 |\n",
    "*      |        3 |  [DRAMA:14, SCI-FI:4] | 2012-06-02 07:20:27 |\n",
    "con esquema:\n",
    "*      |-- movie_id: string\n",
    "*      |-- tag_count: array\n",
    "*      |    |-- element: string\n",
    "*      |-- min_time_tag: timestamp\n",
    "La segunda tabla deberá tener la siguiente estructura:\n",
    "*      | movie_id |                   tag_count |        min_time_tag |\n",
    "*      |        1 | [{SCI-FI, 2}, {TERROR, 12}] | 2017-06-02 07:20:27 |\n",
    "*      |        3 |  [{DRAMA, 14}, {SCI-FI, 4}] | 2012-06-02 07:20:27 |\n",
    "con esquema:\n",
    "*      |-- movie_id: string\n",
    "*      |-- tag_count: array\n",
    "*      |    |-- element: struct\n",
    "*      |    |    |-- tag: string\n",
    "*      |    |    |-- count: long\n",
    "*      |-- min_time_tag: timestamp\n",
    "- ##### NOTA: Ordena la columna tag_count, la cual es un array, de forma ascendente.\n",
    "- #### La generación de la primer tabla es a través del método con la firma:\n",
    "    - ##### def getAct3Df1(df: DataFrame): DataFrame\n",
    "- #### La generación de la segunda tabla es a través del método con la firma:\n",
    "    - ##### def getAct3Df2(df: DataFrame): DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a99bc8-bf57-47c3-95c7-4e67e013087f",
   "metadata": {},
   "source": [
    "#### La siguiente información muestra los pasos recomendados para resolver la actividad 3, puedes omitir leer esta parte si asi lo consideras.\n",
    "##### Para generar ambas tablas primero necesitamos obtener el total veces (count) en las que un \"tag\" se repite por cada \"movie_id\", para evitar conteos erroneos hay que convertir cada tag en Mayusculas.\n",
    "##### El dataframe resultante deberá contener la siguiente estructura: \"movie_id\", \"tag\", \"count\" y \"min\" donde la columna \"count\" representa el total de veces que aparecen cada \"tag\"y \"movie_id\"; la columna \"min\" representa el valor mínimo de cada \"tag\" y \"movie_id\".\n",
    "Por ejemplo, dado el dataframe de entrada\n",
    "*      |user_id|movie_id|   tag|               time|\n",
    "*      |    183|     100|sci-fi|2012-06-02 07:20:27|\n",
    "*      |     12|     832| Drama|2017-06-01 07:20:27|\n",
    "*      |    251|     100|SCI-FI|2009-06-04 07:20:27|\n",
    "*      |    265|     832| DRAMA|2015-06-08 07:20:27|\n",
    "*      |     22|     100|terror|2020-06-06 07:20:27|\n",
    "\n",
    "debemos obtener el siguiente dataframe (el nombre de columnas \"count\" y \"min\" podria ser distinto):\n",
    "\n",
    "*      | movie_id |    tag | count |                 min |\n",
    "*      |      100 | TERROR |     1 | 2020-06-06 07:20:27 |\n",
    "*      |      100 | SCI-FI |     2 | 2009-06-04 07:20:27 |\n",
    "*      |      832 |  DRAMA |     2 | 2015-06-08 07:20:27 |\n",
    "\n",
    "##### Para generar la primer tabla necesitamos concatenar las columnas \"tag\" y \"count\", posteriormente agrupando por \"movie_id\" generaremos la lista de elementos requerida. La columna \"min_time_tag\" representa el valor mínimo de cada \"movie_id\".\n",
    "- ##### Funciones de Spark recomendadas:\n",
    "    - upper -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.upper.html#pyspark.sql.functions.upper\n",
    "    - concat_ws -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat_ws.html#pyspark.sql.functions.concat_ws\n",
    "    - concat -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat.html#pyspark.sql.functions.concat\n",
    "    - collect_list -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_list.html#pyspark.sql.functions.collect_list\n",
    "    - collect_set -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_set.html#pyspark.sql.functions.collect_set##### \n",
    "    - sort_array -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sort_array.html#pyspark-sql-functions-sort-array\n",
    "##### La primer tabla quedará estructurada de la siguiente manera, donde la columna \"tag_count\" es de tipo ArrayType(StringType()) y la columna \"min_time_tag\" es de tipo TimestampType():\n",
    "Dado el dataframe de entrada\n",
    "*      | movie_id |    tag | count |                 min |\n",
    "*      |        1 | TERROR |    12 | 2020-06-06 07:20:27 |\n",
    "*      |        1 | SCI-FI |     2 | 2015-06-06 07:20:27 |\n",
    "*      |        3 |  DRAMA |    14 | 2004-06-06 07:20:27 |\n",
    "*      |        3 | SCI-FI |     4 | 2012-06-06 07:20:27 |\n",
    "debemos obtener el siguiente dataframe\n",
    "*       | movie_id |             tag_count |        min_time_tag |\n",
    "*       |        1 | [SCI-FI:2, TERROR:12] | 2015-06-06 07:20:27 |\n",
    "*       |        3 |  [DRAMA:14, SCI-FI:4] | 2004-06-06 07:20:27 |\n",
    "##### Para generar la segunda tabla necesitamos agregar en una estructura las columnas \"tag\" y \"count\", posteriormente agrupando por movie_id generaremos la lista de elementos requerida. La columna \"min_time_tag\" representa el valor mínimo de cada \"movie_id\".\n",
    "- ##### Funciones de Spark recomendadas:\n",
    "    - upper -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.upper.html#pyspark.sql.functions.upper\n",
    "    - struct -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.struct.html#pyspark.sql.functions.struct\n",
    "    - collect_list -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_list.html#pyspark.sql.functions.collect_list\n",
    "    - collect_set -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_set.html#pyspark.sql.functions.collect_set\n",
    "    - sort_array -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sort_array.html#pyspark-sql-functions-sort-array\n",
    "##### La segunda tabla quedará estructurada de la siguiente manera, donde la columna \"tag_count\" de tipo ArrayType(StructType(StringType(),LongType()))  y la columna \"min_time_tag\" es de tipo TimestampType():\n",
    "Dado el dataframe de entrada\n",
    "*      | movie_id |    tag | count |                 min |\n",
    "*      |        1 | TERROR |    12 | 2020-06-06 07:20:27 |\n",
    "*      |        1 | SCI-FI |     2 | 2015-06-06 07:20:27 |\n",
    "*      |        3 |  DRAMA |    14 | 2004-06-06 07:20:27 |\n",
    "*      |        3 | SCI-FI |     4 | 2012-06-06 07:20:27 |\n",
    "debemos obtener el siguiente dataframe\n",
    "*      | movie_id |                   tag_count |        min_time_tag |\n",
    "*      |        1 | [{SCI-FI, 2}, {TERROR, 12}] | 2015-06-06 07:20:27 |\n",
    "*      |        3 |  [{DRAMA, 14}, {SCI-FI, 4}] | 2004-06-06 07:20:27 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "125e5d81-6c6a-4e23-ad26-2da273a001e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "act3Df2 = [movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "getAct3Df1: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\r\n",
       "getAct3Df2: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\r\n",
       "act3Df1: org.apache.spark.sql.DataFrame = [movie_id: string, tag_count: array<string> ... 1 more field]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 1 more field]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA, PUEDES GENERAR MÉTODOS O VARIABLES NUEVAS SI ASI LO REQUIERES\n",
    "\n",
    "def getAct3Df1(df: DataFrame): DataFrame ={\n",
    "    val mttDF = df\n",
    "        .groupBy(f.col(\"movie_id\"), f.upper(f.col(\"tag\")).alias(\"tag\"))\n",
    "        .agg(\n",
    "            f.count(f.col(\"tag\")).alias(\"count\"),\n",
    "            f.min(\"time\").alias(\"min\")\n",
    "        ).select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.concat_ws(\" : \", f.col(\"tag\"),f.col(\"count\")).alias(\"tag_count\"),\n",
    "            f.col(\"min\").alias(\"min_tag\")\n",
    "        )\n",
    "    val tabla1Df = mttDF\n",
    "        .groupBy(f.col(\"movie_id\"))\n",
    "        .agg(\n",
    "            f.sort_array(f.collect_set(\"tag_count\")).alias(\"tag_count\"),\n",
    "            f.min(\"min_tag\").alias(\"min_time_tag\"),\n",
    "        )\n",
    "    return tabla1Df\n",
    "}\n",
    "\n",
    "def getAct3Df2(df: DataFrame): DataFrame = {\n",
    "    val mtt2Df = df\n",
    "        .groupBy(f.col(\"movie_id\"), f.upper(f.col(\"tag\")).alias(\"tag\"))\n",
    "        .agg(\n",
    "            f.count(f.col(\"tag\")).alias(\"count\"),\n",
    "            f.min(\"time\").alias(\"min\")\n",
    "        ).select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.struct(f.col(\"tag\"),f.col(\"count\")).alias(\"struct\"),\n",
    "            f.col(\"min\").alias(\"min_tag\")\n",
    "        )\n",
    "    val tabla2Df = mtt2Df\n",
    "        .groupBy(f.col(\"movie_id\"))\n",
    "        .agg(\n",
    "            f.sort_array(f.collect_set(\"struct\")).alias(\"tag_count\"),\n",
    "            f.min(\"min_tag\").alias(\"min_time_tag\")\n",
    "        )\n",
    "    return tabla2Df\n",
    "}\n",
    "\n",
    "\n",
    "val act3Df1: DataFrame = getAct3Df1(tagsDf)\n",
    "val act3Df2: DataFrame = getAct3Df2(tagsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8eaf6e9f-0e3d-46c6-a707-127584b431e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                         |min_time_tag       |\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
      "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                             |min_time_tag       |\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
      "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- tag_count: array (nullable = false)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- min_time_tag: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movie_id: string (nullable = true)\n",
      " |-- tag_count: array (nullable = false)\n",
      " |    |-- element: struct (containsNull = false)\n",
      " |    |    |-- tag: string (nullable = true)\n",
      " |    |    |-- count: long (nullable = false)\n",
      " |-- min_time_tag: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act3Df1.show(2, false)\n",
    "act3Df2.show(2, false)\n",
    "act3Df1.printSchema()\n",
    "act3Df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c45e9bc-cd80-4e9f-9024-613aaf1f63a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                         |min_time_tag       |\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
      "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                             |min_time_tag       |\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
      "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "act3Df1.show(2, false)\n",
    "act3Df2.show(2, false)\n",
    "/*\"\"\"\n",
    "Ejemplo de salida esperada:\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                         |min_time_tag       |\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
    "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
    "+--------+------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|movie_id|tag_count                                                             |min_time_tag       |\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
    "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
    "+--------+----------------------------------------------------------------------+-------------------+\n",
    "only showing top 2 rows\n",
    "\"\"\"*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a5ead994-12cb-46be-a2a6-16eb5eeb9cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.AssertionError",
     "evalue": "assertion failed",
     "output_type": "error",
     "traceback": [
      "java.lang.AssertionError: assertion failed\r",
      "  at scala.Predef$.assert(Predef.scala:208)\r",
      "  ... 40 elided"
     ]
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val expectedValueDf1 = Seq(Row(\"100070\",\n",
    "                               List(\"COMEDIAN : 2\",\n",
    "                                    \"COMEDY : 1\",\n",
    "                                    \"GOOD HUMOUR : 1\",\n",
    "                                    \"STRUGGLING CAREER : 1\"),\n",
    "                               Timestamp.valueOf(\"2017-05-19 17:17:36.0\")))\n",
    "val schemaDf1 = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"min_time_tag\", t.TimestampType)\n",
    "))\n",
    "assert(act3Df1.columns.size == 3)\n",
    "assert(act3Df1.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(act3Df1.columns.toSeq.contains(\"tag_count\"))\n",
    "assert(act3Df1.columns.toSeq.contains(\"min_time_tag\"))\n",
    "assert(schema_to_ddl(act3Df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == \"movie_id STRING,tag_count ARRAY<STRING>,min_time_tag TIMESTAMP\")\n",
    "assert(act3Df1.count() == 53452)\n",
    "val testDf1 = spark.createDataFrame(spark.sparkContext.parallelize(expectedValueDf1), schemaDf1)\n",
    "assert(act3Df1.select(\"movie_id\", \"tag_count\", \"min_time_tag\").filter(f.col(\"movie_id\") === \"100070\").except(testDf1).count() == 0)\n",
    "\n",
    "val expectedValueDf2 = Seq(Row(\"100070\",\n",
    "                               List(Row(\"COMEDIAN\",2L),\n",
    "                                    Row(\"COMEDY\",1L),\n",
    "                                    Row(\"GOOD HUMOUR\",1L),\n",
    "                                    Row(\"STRUGGLING CAREER\",1L)),\n",
    "                               Timestamp.valueOf(\"2017-05-19 17:17:36.0\")))\n",
    "val schemaDf2 = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.TimestampType)\n",
    "))\n",
    "assert(act3Df2.columns.size == 3)\n",
    "assert(act3Df2.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(act3Df2.columns.toSeq.contains(\"tag_count\"))\n",
    "assert(act3Df2.columns.toSeq.contains(\"min_time_tag\"))\n",
    "assert(schema_to_ddl(act3Df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\")) == \"movie_id STRING,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,min_time_tag TIMESTAMP\")\n",
    "assert(act3Df2.count() == 53452)\n",
    "val testDf2 = spark.createDataFrame(spark.sparkContext.parallelize(expectedValueDf2), schemaDf2)\n",
    "assert(act3Df2.select(\"movie_id\", \"tag_count\", \"min_time_tag\").filter(f.col(\"movie_id\") === \"100070\").except(testDf2).count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a5e31-597f-4117-b460-df940f85f2da",
   "metadata": {},
   "source": [
    "#### Actividad 4:\n",
    "##### TO DO -> El cliente ha solicitado que resolvamos dos consultas con la salida de la actividad 3, como no especificó con cuál dataframe requiere la consulta lo realizaremos con ambos dataframes (act3Df1 y act3Df2).\n",
    "##### Las consultas a resolver son:\n",
    "- ##### 1.- ¿Cuál es la pelicula (movie_id) con más tags con el valor \"SCI-FI\"?\n",
    "    - ##### Estrictamente especificó no tomar en cuenta datos como \"REALISTIC SCI-FI\", \"HARD SCI-FI\", etc.\n",
    "- ##### 2.- ¿Cuántas peliculas fueron etiquetadas como \"SCI-FI\"?\n",
    "##### La forma de resolver estas consultas será a través de un método el cual va a retornar una tupla (str, int), donde el primer elemento (str) representa el resultado de la consulta 1 y el segundo elemento (int) representa el resultado de la consulta 2\n",
    "- ##### La firma del método que utilizará cada dataFrame es:\n",
    "    - ##### def exercise4Df1(df: DataFrame): (String, Long) -> firma para el dataFrame act3Df1\n",
    "    - ##### def exercise4Df2(df: DataFrame): (String, Long) -> firma para el dataFrame act3Df2\n",
    "##### Funciones de Spark recomendadas:\n",
    "- explode -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.explode.html#pyspark-sql-functions-explode\n",
    "- regexp_extract -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_extract.html#pyspark.sql.functions.regexp_extract\n",
    "##### Funciones de la clase Column recomendadas:\n",
    "- like -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.like.html#pyspark.sql.Column.like\n",
    "- ilike -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.ilike.html#pyspark.sql.Column.ilike\n",
    "- getField -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Column.getField.html#pyspark.sql.Column.getField\n",
    "##### Acciones que podrias utilizar:\n",
    "- count, first, head, take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ca25a50c-3254-4837-8e31-dd95f4681b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                         |min_time_tag       |\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "|100062  |[FATE : 1, PRESS-GANGED : 1, WAR : 1, WORLD WAR II : 1]           |2018-05-26 16:40:54|\n",
      "|100070  |[COMEDIAN : 2, COMEDY : 1, GOOD HUMOUR : 1, STRUGGLING CAREER : 1]|2017-05-19 17:17:36|\n",
      "+--------+------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|movie_id|tag_count                                                             |min_time_tag       |\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "|100062  |[{FATE, 1}, {PRESS-GANGED, 1}, {WAR, 1}, {WORLD WAR II, 1}]           |2018-05-26 16:40:54|\n",
      "|100070  |[{COMEDIAN, 2}, {COMEDY, 1}, {GOOD HUMOUR, 1}, {STRUGGLING CAREER, 1}]|2017-05-19 17:17:36|\n",
      "+--------+----------------------------------------------------------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "act3Df1.show(2, false)\n",
    "act3Df2.show(2, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ed8701f0-c9e5-4561-bafe-97346f3552d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exercise4Df1: (df: org.apache.spark.sql.DataFrame)(String, Long)\r\n",
       "exercise4Df2: (df: org.apache.spark.sql.DataFrame)(String, Long)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA, PUEDES GENERAR MÉTODOS O VARIABLES SI ASI LO REQUIERES\n",
    "\n",
    "def exercise4Df1(df: DataFrame): (String, Long) = {\n",
    "    val ex4Df1 = df\n",
    "        .select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.explode(f.col(\"tag_count\")).alias(\"tag\")\n",
    "        )\n",
    "        .select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.col(\"tag\"),\n",
    "            f.regexp_extract(f.col(\"tag\"), \"[0-9]*$\", 0).cast(t.IntegerType).alias(\"tot\")\n",
    "        )\n",
    "        .filter(f.col(\"tag\").like(\"SCI-FI : %\"))\n",
    "        .orderBy(f.col(\"tot\").desc)\n",
    "    return (ex4Df1.first.getAs[String](\"movie_id\"), ex4Df1.count()) // modificar codigo interno\n",
    "}\n",
    "\n",
    "def exercise4Df2(df: DataFrame): (String, Long) = {\n",
    "    val ex4Df2 = df\n",
    "        .select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.explode(f.col(\"tag_count\")).alias(\"tag\")\n",
    "        )\n",
    "        .select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.col(\"tag\").getField(\"tag\"),\n",
    "            f.col(\"tag\").getField(\"count\")\n",
    "        )\n",
    "        .filter(f.col(\"tag.tag\").like(\"SCI-FI\"))\n",
    "        .orderBy(f.col(\"tag.count\").desc)\n",
    "    return (ex4Df2.first.getAs[String](\"movie_id\"), ex4Df2.count())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c8378f9d-5823-43db-b8cf-86c3cdf99e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260,854)\n",
      "(260,854)\n"
     ]
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "println(exercise4Df1(act3Df1))\n",
    "println(exercise4Df2(act3Df2))\n",
    "// Salida esperada en ambos casos\n",
    "//('260', 854)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66df8125-9055-445b-8afe-aa8d123b8412",
   "metadata": {},
   "outputs": [],
   "source": [
    "val resultExercise4Df1 = exercise4Df1(act3Df1)\n",
    "assert(resultExercise4Df1._1 == \"260\")\n",
    "assert(resultExercise4Df1._2 == 854)\n",
    "\n",
    "val resultExercise4Df2 = exercise4Df2(act3Df2)\n",
    "assert(resultExercise4Df2._1 == \"260\")\n",
    "assert(resultExercise4Df2._2 == 854)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f87e6-bdcf-4567-a8fe-56d4f1aa36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((moviesDf, \"07/movies\"),\n",
    "              (act3Df1, \"07/tags_p1\"),\n",
    "              (act3Df2, \"07/tags_p2\"),\n",
    "              (calculateRatingValues(ratingsDf), \"07/ratings\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b76900e-7ba9-4d99-bb20-2540cca7d4a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
