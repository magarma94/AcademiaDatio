{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38577af2-d648-4b03-82b5-f44adadae9b0",
   "metadata": {},
   "source": [
    "#### Hasta este punto tenemos nuestras tablas procesadas (movies, ratings y tags) de forma correcta. El cliente nos ha solicitado apoyar al departamento de Marketing a realizar algunas consultas y a generar una única tabla y realizar algunos ajustes a la tabla final antes de poder almacenarla.\n",
    "\n",
    "##### Nota: Para poder trabajar con este notebook es necesario haber terminado el ejercicio de la sesión 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7aed2b-a75e-4a30-ba90-d6a21f55965b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%HTML <style>pre { white-space: pre !important; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c5e3c8-5689-4c7c-83d3-ec7b70d0e1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>f}\r\n",
       "import org.apache.spark.sql.{types=>t}\r\n",
       "difference: (l1: Seq[String], l2: Seq[String])Seq[org.apache.spark.sql.Column]\r\n",
       "readTmpDf: (dfSeq: Seq[String])Map[String,org.apache.spark.sql.DataFrame]\r\n",
       "writeTmpDf: (dfSeq: Seq[(org.apache.spark.sql.DataFrame, String)])Unit\r\n",
       "schema_to_ddl: (df: org.apache.spark.sql.DataFrame)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR CONTENIDO DE ESTA CELDA\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Column, Row}\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "import org.apache.spark.sql.{types => t}\n",
    "\n",
    "def difference(l1: Seq[String], l2: Seq[String]): Seq[Column] =\n",
    "    l1.diff(l2).map(colName => f.col(colName))\n",
    "\n",
    "def readTmpDf(dfSeq: Seq[String]): Map[String, DataFrame] =\n",
    "    dfSeq.map(table_name => (table_name, spark.read.parquet(\"../../resources/data/tmp/parquet/\" + table_name))).toMap\n",
    "\n",
    "def writeTmpDf(dfSeq: Seq[(DataFrame, String)]): Unit = \n",
    "    dfSeq.foreach{case (df: DataFrame, name: String) => df.write.mode(\"overwrite\").parquet(\"../../resources/data/tmp/parquet/\" + name)}\n",
    "\n",
    "def schema_to_ddl(df: DataFrame): String = df.schema.toDDL.replace(\" NOT NULL\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f34787-67c5-4d2b-a592-4f29e250e95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|movie_id|title           |genres                                           |year|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "|1       |Toy Story (1995)|[Adventure, Animation, Children, Comedy, Fantasy]|1995|\n",
      "+--------+----------------+-------------------------------------------------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "|    1049|       3.4|         0.97|        5816|1996-10-10 02:58:19|\n",
      "+--------+----------+-------------+------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+--------+--------------------+-------------------+\n",
      "|movie_id|           tag_count|       min_time_tag|\n",
      "+--------+--------------------+-------------------+\n",
      "|  100001|[{PERFORMANCE (MO...|2018-05-18 00:40:21|\n",
      "+--------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tagsDf = [movie_id: string, tag_count: array<struct<tag:string,...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@194557fd\r\n",
       "RootPath: String = ../../resources/data/tmp/parquet/\r\n",
       "namesList: Seq[String] = List(07/movies, 07/ratings, 07/tags_p2)\r\n",
       "dfMap: Map[String,org.apache.spark.sql.DataFrame] = Map(07/movies -> [movie_id: string, title: string ... 2 more fields], 07/ratings -> [movie_id: string, avg_rating: double ... 3 more fields], 07/tags_p2 -> [movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 1 more field])\r\n",
       "moviesDf: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 2 more fields]\r\n",
       "ratingsDf: org.apache.spark.sql.DataFrame = [movie_id: string, avg_rating: double ... 3 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, tag_count: array<struct<tag:string,..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "// Creación de sesión de Spark\n",
    "val spark = SparkSession.builder\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"ejercicio_8\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"GMT-6\")\n",
    "\n",
    "// Carga de tablas requeridas\n",
    "val RootPath = \"../../resources/data/tmp/parquet/\"\n",
    "val namesList = Seq(\"07/movies\", \"07/ratings\", \"07/tags_p2\")\n",
    "val dfMap = readTmpDf(namesList)\n",
    "\n",
    "val moviesDf = dfMap(\"07/movies\")\n",
    "val ratingsDf = dfMap(\"07/ratings\")\n",
    "val tagsDf = dfMap(\"07/tags_p2\")\n",
    "\n",
    "moviesDf.show(1, false)\n",
    "ratingsDf.show(1)\n",
    "tagsDf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71d4d1-826a-4993-bc6e-ee87939e3525",
   "metadata": {},
   "source": [
    "#### En la siguiente imagen se muestra una representación a traves del diagrama de Venn sobre cada tabla (moviesDf, ratingsDf y tagsDf) la cual fue contruida por el departamento de Marketing, el problema es que no saben la cantidad de datos de cada conjunto.\n",
    "##### El cliente nos han solicitado obtener la cantidad de registros de cada conjunto de datos representado por las siguientes letras:\n",
    "- ##### A: Registros de moviesDf que no tiene filas coincidentes con las tablas ratingsDf y tagsDf\n",
    "- ##### B: Registros de ratingsDf que no tiene filas coincidentes con las tablas moviesDf y tagsDf\n",
    "- ##### C: Registros de tagsDf que no tiene filas coincidentes con las tablas moviesDf y ratingsDf\n",
    "- ##### D: Registros de moviesDf y ratingsDf que no tiene filas coincidentes con la tabla tagsDf\n",
    "- ##### E: Registros de moviesDf y tagsDf que no tiene filas coincidentes con la tabla ratingsDf\n",
    "- ##### F: Registros de ratingsDf y tagsDf que no tiene filas coincidentes con la tabla moviesDf\n",
    "- ##### G: Registros que contiene datos coincidentes en las tablas moviesDf, ratingsDf y tagsDf\n",
    "-  Una tabla tiene registros coincidentes con otra cuando comparten el mismo valor en la columna \"movie_id\"\n",
    "\n",
    "![title](../../resources/img/Tablas_conjuntos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07f716-9806-4388-ad1a-b0fa9f4266cf",
   "metadata": {},
   "source": [
    "#### Actividad 1:\n",
    "##### TO DO ->    Obtener los conjuntos de datos listados en el diagrama de Venn con operaciones de tipo join, con la finalidad de ahorrar recursos el cliente nos ha solicitado que en la salida de cada transformación el dataframe resultante contenga únicamente la columna \"movie_id\" (basta con utilizar únicante una trasnsformación select al inicio de las operaciones join y utilizar únicamente joins del tipo **left_semi** y **left_anti**).\n",
    "- ##### Los dataframes resultantes se almacenarán en las siguientes variables:\n",
    "    - ##### A_df -> Conjunto A\n",
    "    - ##### B_df -> Conjunto B\n",
    "    - ##### C_df -> Conjunto C\n",
    "    - ##### D_df -> Conjunto D\n",
    "    - ##### E_df -> Conjunto E\n",
    "    - ##### F_df -> Conjunto F\n",
    "    - ##### G_df -> Conjunto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1cd39b6-c0ee-4fad-9320-f933a6f6c8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operacionConjuntosCaso1: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Método para conjuntos A, B y C:\n",
    "def operacionConjuntosCaso1(df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = {\n",
    "    val df1JoinDf2 = df1.select(\"movie_id\").join(df2,Seq(\"movie_id\"),\"left_semi\")\n",
    "    val df1JoinDf3 = df1.select(\"movie_id\").join(df3,Seq(\"movie_id\"),\"left_semi\")\n",
    "    val restaJoinsDf1jdf2Df1jdf3 = df1.select(\"movie_id\")\n",
    "        .join(df1JoinDf2,Seq(\"movie_id\"),\"left_anti\")\n",
    "        .join(df1JoinDf3,Seq(\"movie_id\"),\"left_anti\")\n",
    "    return restaJoinsDf1jdf2Df1jdf3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78b719f6-eabb-4192-83e8-4c26f002c43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "+--------+\n",
      "\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "casoA = [movie_id: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val casoA = operacionConjuntosCaso1(moviesDf, ratingsDf, tagsDf)\n",
    "casoA.show()\n",
    "println(casoA.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5c5faf8-a015-4f2d-ba0a-a72875502c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operacionConjuntosCaso2: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Método para conjuntos D, E y F:\n",
    "def operacionConjuntosCaso2(df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = {\n",
    "    val df1_join_df2 = df1.select(\"movie_id\").join(df2,Seq(\"movie_id\"),\"left_semi\")\n",
    "    val resta_joins_df1jdf2 = df1_join_df2.select(\"movie_id\").join(df3,Seq(\"movie_id\"),\"left_anti\")\n",
    "    return resta_joins_df1jdf2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e512af79-f6f0-4427-b2cc-95b45ea9ef8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|      51|\n",
      "+--------+\n",
      "only showing top 1 row\n",
      "\n",
      "28815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "casoC = [movie_id: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Caso C:\n",
    "val casoC = operacionConjuntosCaso2(moviesDf, ratingsDf, tagsDf)\n",
    "casoC.show(1)\n",
    "println(casoC.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdc26d3b-266b-491f-b56f-05106d64f502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operacionConjuntosCaso3: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Método para conjunto G:\n",
    "def operacionConjuntosCaso3(df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = { \n",
    "    val df1_join_df2 = df1.select(\"movie_id\").join(df2,Seq(\"movie_id\"),\"left_semi\")\n",
    "    val df1jdf2_join_df3 = df1_join_df2.select(\"movie_id\").join(df3,Seq(\"movie_id\"),\"left_semi\")\n",
    "    return df1jdf2_join_df3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6129f5c0-1624-4b57-809e-c63531f347f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|       1|\n",
      "+--------+\n",
      "only showing top 1 row\n",
      "\n",
      "47903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "casoG = [movie_id: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val casoG = operacionConjuntosCaso3(moviesDf,ratingsDf,tagsDf)\n",
    "casoG.show(1)\n",
    "println(casoG.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a5bb862-0181-4a7e-86bd-1611fe915f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gdf = [movie_id: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "Adf: org.apache.spark.sql.DataFrame = [movie_id: string]\r\n",
       "Bdf: org.apache.spark.sql.DataFrame = [movie_id: string]\r\n",
       "Cdf: org.apache.spark.sql.DataFrame = [movie_id: string]\r\n",
       "Ddf: org.apache.spark.sql.DataFrame = [movie_id: string]\r\n",
       "Edf: org.apache.spark.sql.DataFrame = [movie_id: string]\r\n",
       "Fdf: org.apache.spark.sql.DataFrame = [movie_id: string]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "// Conjunto A:\n",
    "val Adf = operacionConjuntosCaso1(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto B:\n",
    "val Bdf = operacionConjuntosCaso1(ratingsDf, moviesDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto C:\n",
    "val Cdf = operacionConjuntosCaso1(tagsDf, moviesDf, ratingsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto D:\n",
    "val Ddf = operacionConjuntosCaso2(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto E:\n",
    "val Edf = operacionConjuntosCaso2(moviesDf, tagsDf, ratingsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto F:\n",
    "val Fdf = operacionConjuntosCaso2(ratingsDf, tagsDf, moviesDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto G:\n",
    "val Gdf = operacionConjuntosCaso3(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f75654c-f84e-4c13-83f2-445301d53f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|movie_id|\n",
      "+--------+\n",
      "|  179995|\n",
      "+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "Bdf.show(1)\n",
    "/*\"\"\"\n",
    "Ejemplo de salida de cada dataframe (desde A hasta G):\n",
    "+--------+\n",
    "|movie_id|\n",
    "+--------+\n",
    "|  179995|\n",
    "+--------+\n",
    "only showing top 1 row\n",
    "\"\"\"*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bec544e2-6d98-427f-a16a-f74588d26ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "assert(Adf.count() == 0)\n",
    "assert(Bdf.count() == 4270)\n",
    "assert(Cdf.count() == 539)\n",
    "assert(Ddf.count() == 28815)\n",
    "assert(Edf.count() == 2759)\n",
    "assert(Fdf.count() == 2251)\n",
    "assert(Gdf.count() == 47903)\n",
    "\n",
    "assert(Adf.columns.size == 1)\n",
    "assert(Bdf.columns.size == 1)\n",
    "assert(Cdf.columns.size == 1)\n",
    "assert(Ddf.columns.size == 1)\n",
    "assert(Edf.columns.size == 1)\n",
    "assert(Fdf.columns.size == 1)\n",
    "assert(Gdf.columns.size == 1)\n",
    "\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))\n",
    "assert(Adf.columns.toSeq.contains(\"movie_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63eaf5-b3fe-4166-93c7-7477a3c38748",
   "metadata": {},
   "source": [
    "#### Actividad 2:\n",
    "##### TO DO ->    Algunos administradores de base de datos no comprenden el uso de los joins de tipo left_semi y left_anti, por lo tanto el cliente ha solicitado que tambien se realicen las transformaciones con cualquiera de los siguientes tipos de join: **left, right, inner, outer**. Podrías utilizar la transformación filter/where en algunos casos.\n",
    "##### No existe alguna reestricción de qué columnas contiene el dataframe de salida.\n",
    "- ##### Los dataframes resultantes se almacenarán en las siguientes variables:\n",
    "    - ##### A_df -> Conjunto A\n",
    "    - ##### B_df -> Conjunto B\n",
    "    - ##### C_df -> Conjunto C\n",
    "    - ##### D_df -> Conjunto D\n",
    "    - ##### E_df -> Conjunto E\n",
    "    - ##### F_df -> Conjunto F\n",
    "    - ##### G_df -> Conjunto G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d05e4-54bf-481d-8f54-5c7a75e08457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6a5a7f9-6879-4918-b63f-df2705badedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\r\n",
       "opConj1: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Operaciones de conjuntos pero sin usar left_semi ni left_anti:\n",
    "// Caso A, B y C con join left:\n",
    "def opConj1 (df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = {\n",
    "    val primera_union = df1.join(df2,Seq(\"movie_id\"),\"left\")\n",
    "    val segunda_union = primera_union.join(df3,Seq(\"movie_id\"),\"left\")\n",
    "    val coincidencias_filtro = segunda_union.filter(df2(\"movie_id\").isNull && df3(\"movie_id\").isNull)\n",
    "    return coincidencias_filtro\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "763a0afd-3e32-469f-b84e-483b524d3a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------+------------+-------------------+-----+------+----+---------+------------+\n",
      "|movie_id|avg_rating|stddev_rating|count_rating|    min_time_rating|title|genres|year|tag_count|min_time_tag|\n",
      "+--------+----------+-------------+------------+-------------------+-----+------+----+---------+------------+\n",
      "|  179995|      3.65|         0.74|          17|2017-11-03 00:43:44| null|  null|null|     null|        null|\n",
      "+--------+----------+-------------+------------+-------------------+-----+------+----+---------+------------+\n",
      "only showing top 1 row\n",
      "\n",
      "4270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "casoB2 = [movie_id: string, avg_rating: double ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, avg_rating: double ... 8 more fields]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Test A:\n",
    "//val casoA2 = opConj1(moviesDf, ratingsDf, tagsDf)\n",
    "//casoA2.show(1)\n",
    "//println(casoA2.count())\n",
    "val casoB2 = opConj1(ratingsDf, moviesDf, tagsDf)\n",
    "casoB2.show(1)\n",
    "println(casoB2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c1913aa-0819-4619-a71c-5e369f8df00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\r\n",
       "opConj2: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Caso D, E y F:\n",
    "/* df.columns sería como df.columns.head, df.columns.tail: _* ya que df.columns regresa un arreglo de nombres de columnas,\n",
    "necesitamos operar sólo con la primer columna y luego obtener el resto*/\n",
    "def opConj2(df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = {\n",
    "    val union_uno = df1.join(df3,Seq(\"movie_id\"),\"left\")\n",
    "    val union_dos = df2.join(df3,Seq(\"movie_id\"),\"left\")\n",
    "    val filtro_uno = union_uno.filter(df3(\"movie_id\").isNull).select(df1.columns.head, df1.columns.tail: _*)\n",
    "    val filtro_dos = union_dos.filter(df3(\"movie_id\").isNull).select(df2.columns.head, df2.columns.tail: _*)\n",
    "    val union_final = filtro_uno.join(filtro_dos,Seq(\"movie_id\"),\"inner\")\n",
    "    return union_final\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4576b3e-bed7-4d37-bb08-509e0639c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------+----+----------+-------------+------------+-------------------+\n",
      "|movie_id|               title|   genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|\n",
      "+--------+--------------------+---------+----+----------+-------------+------------+-------------------+\n",
      "|    1159|Love in Bloom (1935)|[Romance]|1935|      2.88|         1.05|          20|1996-10-11 04:28:21|\n",
      "+--------+--------------------+---------+----+----------+-------------+------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "28815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "casoD2 = [movie_id: string, title: string ... 6 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 6 more fields]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Test:\n",
    "val casoD2 = opConj2(moviesDf, ratingsDf, tagsDf)\n",
    "//val casoE2 = opConj2(moviesDf, tagsDf, ratingsDf)\n",
    "//val casoF2 = opConj2(ratingsDf, tagsDf, moviesDf)\n",
    "casoD2.show(1)\n",
    "println(casoD2.count())\n",
    "//casoE2.show(1)\n",
    "//println(casoE2.count())\n",
    "//casoF2.show(1)\n",
    "//println(casoF2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcf547c5-f016-42a8-a100-2c4cd1f69a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opConj3: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "//Caso G - Registros que contiene datos coincidentes en las tablas movies_df, ratings_df y tags_df:\n",
    "def opConj3(df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = {\n",
    "    val union_uno = df1.join(df2,Seq(\"movie_id\"), \"inner\")\n",
    "    val union_dos = union_uno.join(df3,Seq(\"movie_id\"),\"inner\")\n",
    "    return union_dos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de35df75-5f96-4721-b9e2-1ae9d42f9bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G_df = [movie_id: string, title: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "A_df: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 8 more fields]\r\n",
       "B_df: org.apache.spark.sql.DataFrame = [movie_id: string, avg_rating: double ... 8 more fields]\r\n",
       "C_df: org.apache.spark.sql.DataFrame = [movie_id: string, tag_count: array<struct<tag:string,count:bigint>> ... 8 more fields]\r\n",
       "D_df: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 6 more fields]\r\n",
       "E_df: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 4 more fields]\r\n",
       "F_df: org.apache.spark.sql.DataFrame = [movie_id: string, avg_rating: double ... 5 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 8 more fields]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "// Conjunto A:\n",
    "val A_df = opConj1(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto B:\n",
    "val B_df = opConj1(ratingsDf, moviesDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto C:\n",
    "val C_df = opConj1(tagsDf, moviesDf, ratingsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto D:\n",
    "val D_df = opConj2(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto E:\n",
    "val E_df = opConj2(moviesDf, tagsDf, ratingsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto F:\n",
    "val F_df = opConj2(ratingsDf, tagsDf, moviesDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf\n",
    "// Conjunto G:\n",
    "val G_df = opConj3(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9ed8ee6-2c1e-435a-bef1-c617303b95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "assert(A_df.count() == 0)\n",
    "assert(B_df.count() == 4270)\n",
    "assert(C_df.count() == 539)\n",
    "assert(D_df.count() == 28815)\n",
    "assert(E_df.count() == 2759)\n",
    "assert(F_df.count() == 2251)\n",
    "assert(G_df.count() == 47903)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2a8be-795b-4217-b5ff-663d8ba63778",
   "metadata": {},
   "source": [
    "#### Actividad 3:\n",
    "##### TO DO ->    Con operaciones join genera un dataframe que contenga la union de todos los conjuntos (desde el A hasta el G) sin repetir registros. No utilices las transformaciones de union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b13a58da-0757-471c-9ac5-4dce1bfb8961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joinUniverso: (df1: org.apache.spark.sql.DataFrame, df2: org.apache.spark.sql.DataFrame, df3: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// Definición de método:\n",
    "def joinUniverso(df1: DataFrame, df2: DataFrame, df3: DataFrame): DataFrame = {\n",
    "    val joinDf1Df2 = df1.join(df2,Seq(\"movie_id\"),\"outer\")\n",
    "    val join_DataFrames = joinDf1Df2.join(df3,Seq(\"movie_id\"),\"outer\")\n",
    "    return join_DataFrames\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f279eea-1ee1-43f3-a360-f9e19be6f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
      "|movie_id|               title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
      "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
      "|  100062|My Way (Mai Wei) ...|[Action, Drama, War]|2011|      3.63|         0.83|          64|2014-03-11 21:23:33|[{FATE, 1}, {PRES...|2018-05-26 16:40:54|\n",
      "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "86537"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TESTval = [movie_id: string, title: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 8 more fields]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TEST:\n",
    "val TESTval = joinUniverso(moviesDf, ratingsDf, tagsDf)\n",
    "TESTval.show(1)\n",
    "print(TESTval.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cc418dd-8cd1-4803-a439-0e7e5cf59437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "universeDf = [movie_id: string, title: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 8 more fields]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "val universeDf = joinUniverso(moviesDf, ratingsDf, tagsDf) // aplicar transformaciones join a moviesDf, ratingsDf y tagsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39cc3bdb-d072-4a6b-bf85-eef22ce25394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
      "|movie_id|               title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
      "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
      "|  100062|My Way (Mai Wei) ...|[Action, Drama, War]|2011|      3.63|         0.83|          64|2014-03-11 21:23:33|[{FATE, 1}, {PRES...|2018-05-26 16:40:54|\n",
      "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\r\n",
       "Ejemplo de salida:\r\n",
       "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\r\n",
       "movie_id|               title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\r\n",
       "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\r\n",
       "  100062|My Way (Mai Wei) ...|[Action, Drama, War]|2011|      3.63|         0.83|          64|2014-03-11 21:23:33|[{PRESS-GANGED, 1...|2018-05-26 16:40:54|\r\n",
       "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+------------...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "universeDf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida:\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|movie_id|               title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|  100062|My Way (Mai Wei) ...|[Action, Drama, War]|2011|      3.63|         0.83|          64|2014-03-11 21:23:33|[{PRESS-GANGED, 1...|2018-05-26 16:40:54|\n",
    "+--------+--------------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "325dfa01-26a2-48bc-ac05-aa5d660f3802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(movie_id,StringType,true),StructField(title,StringType,true),StructField(genres,ArrayType(StringType,true),true),StructField(year,IntegerType,true),StructField(avg_rating,DoubleType,true),StructField(stddev_rating,DoubleType,true),StructField(count_rating,LongType,true),StructField(min_time_rating,StringType,true),StructField(tag_count,ArrayType(StructType(StructField(tag,StringType,true),StructField(count,LongType,true)),true),true),StructField(min_time_tag,StringType,...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\r\n",
       "data: Seq[org.apache.spark.sql.Row] = List([100062,My Way (Mai Wei) (2011),List(Action, Drama, War),2011,3.63,0.83,64,2014-03-11 21:23:33.0,List([FATE,1], [PRESS-GANGED,1], [WAR,1], [WORLD WAR II,1]),2018-05-26 16:40:54.0])\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(movie_id,StringType,true),StructField(title,StringType,true),StructField(genres,ArrayType(StringType,true),true),StructField(year,IntegerType,true),StructField(avg_rating,DoubleType,true),StructField(stddev_rating,DoubleType,true),StructField(count_rating,LongType,true),StructField(min_time_rating,StringType,true),StructField(tag_count,ArrayType(StructType(StructField(tag,StringType,true),StructField(count,LongType,true)),true),true),StructField(min_time_tag,StringType,..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val data = Seq(Row(\"100062\",\n",
    "                   \"My Way (Mai Wei) (2011)\",\n",
    "                   Seq(\"Action\", \"Drama\", \"War\"),\n",
    "                   2011,\n",
    "                   3.63,\n",
    "                   0.83,\n",
    "                   64L,\n",
    "                   (\"2014-03-11 21:23:33.0\"),\n",
    "                   Seq(Row(\"FATE\",1L),\n",
    "                       Row(\"PRESS-GANGED\",1L),\n",
    "                       Row(\"WAR\",1L),\n",
    "                       Row(\"WORLD WAR II\",1L)),\n",
    "                   (\"2018-05-26 16:40:54.0\")))\n",
    "val schema = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"title\", t.StringType),\n",
    "    t.StructField(\"genres\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"year\", t.IntegerType),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType),\n",
    "    t.StructField(\"count_rating\", t.LongType),\n",
    "    t.StructField(\"min_time_rating\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.StringType)\n",
    "    ))\n",
    "val testDf = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n",
    "    .withColumn(\"min_time_rating\", f.col(\"min_time_rating\").cast(t.TimestampType))\n",
    "    .withColumn(\"min_time_tag\", f.col(\"min_time_tag\").cast(t.TimestampType))\n",
    "\n",
    "val expectedColumns = Seq(\"movie_id\", \"title\", \"genres\", \"year\",\n",
    "                          \"avg_rating\", \"stddev_rating\", \"count_rating\",\n",
    "                          \"min_time_rating\", \"tag_count\", \"min_time_tag\")\n",
    "\n",
    "assert(universeDf.count() == 86537)\n",
    "assert(universeDf.columns.diff(expectedColumns).size + expectedColumns.diff(universeDf.columns).size == 0)\n",
    "assert(universeDf\n",
    "    .select(expectedColumns.map(f.col):_*)\n",
    "    .filter(f.col(\"movie_id\") === \"100062\")\n",
    "    .except(testDf).count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc31f99-4163-4721-b33d-b1ecdc8d4b05",
   "metadata": {},
   "source": [
    "#### Actividad 4:\n",
    "##### TO DO ->    La estructura del dataframe final de acuerdo al análisis realizado por marketing es el dado por la union del conjunto de datos: A, D, E y G. Realiza este proceso y almacena el dataframe resultante en la variable \"finalDf\"\n",
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43cbcee5-b638-4887-9854-241b5ec9b931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G_df = [movie_id: string, title: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "A_df: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 8 more fields]\r\n",
       "D_df: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 6 more fields]\r\n",
       "E_df: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 4 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 8 more fields]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Definiciones:\n",
    "val A_df = opConj1(moviesDf, ratingsDf, tagsDf)\n",
    "val D_df = opConj2(moviesDf, ratingsDf, tagsDf)\n",
    "val E_df = opConj2(moviesDf, tagsDf, ratingsDf)\n",
    "val G_df = opConj3(moviesDf, ratingsDf, tagsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8df266a-aef7-4f3f-8f28-e91060f1c03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finalDf = [movie_id: string, title: string ... 8 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "unionUno: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [movie_id: string, title: string ... 8 more fields]\r\n",
       "unionDos: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [movie_id: string, title: string ... 8 more fields]\r\n",
       "unionTres: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [movie_id: string, title: string ... 8 more fields]\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[movie_id: string, title: string ... 8 more fields]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "// aplicar transformaciones join a movies_df, ratings_df y tags_df\n",
    "val unionUno = A_df.unionByName(D_df, allowMissingColumns  = true)\n",
    "val unionDos = unionUno.unionByName(E_df, allowMissingColumns  = true)\n",
    "val unionTres = unionDos.unionByName(G_df, allowMissingColumns  = true)\n",
    "val finalDf = unionTres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2cade6f4-ba10-47be-a2e9-f37e0f1ebbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------+----+----------+-------------+------------+-------------------+---------+------------+\n",
      "|movie_id|               title|   genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|tag_count|min_time_tag|\n",
      "+--------+--------------------+---------+----+----------+-------------+------------+-------------------+---------+------------+\n",
      "|    1159|Love in Bloom (1935)|[Romance]|1935|      2.88|         1.05|          20|1996-10-11 04:28:21|     null|        null|\n",
      "+--------+--------------------+---------+----+----------+-------------+------------+-------------------+---------+------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\r\n",
       "Ejemplo de salida:\r\n",
       "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\r\n",
       "movie_id|           title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\r\n",
       "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\r\n",
       "       1|Toy Story (1995)|[Adventure, Anima...|1995|      3.89|         0.93|       76813|1996-01-28 18:00:00|[{TIME TRAVEL, 11...|2006-01-12 19:19:35|\r\n",
       "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-----------...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "finalDf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida:\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|movie_id|           title|              genres|year|avg_rating|stddev_rating|count_rating|    min_time_rating|           tag_count|       min_time_tag|\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "|       1|Toy Story (1995)|[Adventure, Anima...|1995|      3.89|         0.93|       76813|1996-01-28 18:00:00|[{TIME TRAVEL, 11...|2006-01-12 19:19:35|\n",
    "+--------+----------------+--------------------+----+----------+-------------+------------+-------------------+--------------------+-------------------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d7f51d7-33e5-4e89-9781-6402060cb841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema = StructType(StructField(movie_id,StringType,true),StructField(title,StringType,true),StructField(genres,ArrayType(StringType,true),true),StructField(year,IntegerType,true),StructField(avg_rating,DoubleType,true),StructField(stddev_rating,DoubleType,true),StructField(count_rating,LongType,true),StructField(min_time_rating,StringType,true),StructField(tag_count,ArrayType(StructType(StructField(tag,StringType,true),StructField(count,LongType,true)),true),true),StructField(min_time_tag,StringType,...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "data: Seq[org.apache.spark.sql.Row] = List([100062,My Way (Mai Wei) (2011),List(Action, Drama, War),2011,3.63,0.83,64,2014-03-11 21:23:33.0,List([FATE,1], [PRESS-GANGED,1], [WAR,1], [WORLD WAR II,1]),2018-05-26 16:40:54.0])\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "StructType(StructField(movie_id,StringType,true),StructField(title,StringType,true),StructField(genres,ArrayType(StringType,true),true),StructField(year,IntegerType,true),StructField(avg_rating,DoubleType,true),StructField(stddev_rating,DoubleType,true),StructField(count_rating,LongType,true),StructField(min_time_rating,StringType,true),StructField(tag_count,ArrayType(StructType(StructField(tag,StringType,true),StructField(count,LongType,true)),true),true),StructField(min_time_tag,StringType,..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val data = Seq(Row(\"100062\",\n",
    "                   \"My Way (Mai Wei) (2011)\",\n",
    "                   Seq(\"Action\", \"Drama\", \"War\"),\n",
    "                   2011,\n",
    "                   3.63,\n",
    "                   0.83,\n",
    "                   64L,\n",
    "                   (\"2014-03-11 21:23:33.0\"),\n",
    "                   Seq(Row(\"FATE\",1L),\n",
    "                       Row(\"PRESS-GANGED\",1L),\n",
    "                       Row(\"WAR\",1L),\n",
    "                       Row(\"WORLD WAR II\",1L)),\n",
    "                   (\"2018-05-26 16:40:54.0\")))\n",
    "val schema = t.StructType(Seq(\n",
    "    t.StructField(\"movie_id\", t.StringType),\n",
    "    t.StructField(\"title\", t.StringType),\n",
    "    t.StructField(\"genres\", t.ArrayType(t.StringType)),\n",
    "    t.StructField(\"year\", t.IntegerType),\n",
    "    t.StructField(\"avg_rating\", t.DoubleType),\n",
    "    t.StructField(\"stddev_rating\", t.DoubleType),\n",
    "    t.StructField(\"count_rating\", t.LongType),\n",
    "    t.StructField(\"min_time_rating\", t.StringType),\n",
    "    t.StructField(\"tag_count\", t.ArrayType(t.StructType(Seq(\n",
    "        t.StructField(\"tag\", t.StringType),\n",
    "        t.StructField(\"count\", t.LongType)\n",
    "    )))),\n",
    "    t.StructField(\"min_time_tag\", t.StringType)\n",
    "    ))\n",
    "val testDf = spark.createDataFrame(spark.sparkContext.parallelize(data), schema)\n",
    "    .withColumn(\"min_time_rating\", f.col(\"min_time_rating\").cast(t.TimestampType))\n",
    "    .withColumn(\"min_time_tag\", f.col(\"min_time_tag\").cast(t.TimestampType))\n",
    "\n",
    "assert(finalDf.count() == 79477)\n",
    "assert(finalDf.columns.diff(expectedColumns).size + expectedColumns.diff(finalDf.columns).size == 0)\n",
    "assert(finalDf\n",
    "    .select(expectedColumns.map(f.col):_*)\n",
    "    .filter(f.col(\"movie_id\") === \"100062\")\n",
    "    .except(testDf).count() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20399c4b-106f-4696-b246-40f949628469",
   "metadata": {},
   "source": [
    "#### Actividad 5:\n",
    "##### TO DO ->    El cliente nos ha solicitado llenar los valores \"null\" de la columna \"year\", para esto nos ha pedido seguir la siguiente regla:\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_rating\" es null colocar el año de la columna \"min_time_tag\".\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_tag\" es null colocar el año de la columna \"min_time_rating\".\n",
    "- ##### Si la columna \"year\" es null, y las columnas \"min_time_rating\" y \"min_time_tag\" son distintas de null colocar el año menor de las columnas \"min_time_rating\" y \"min_time_tag\", en caso de que el año en ambas columnas sea el mismo colocar dicho año.\n",
    "- ##### En cualquier otro caso mantener el valor entero 1970\n",
    "##### Adicional nos ha solicitado generar una columna llamada \"year_type\" con los siguientes valores:\n",
    "- ##### Si la columna \"year\" venia con un valor distinto a null, asignar el valor \"YO\"\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_rating\" es null colocar \"YT\"\n",
    "- ##### Si la columna \"year\" es null y si la columna \"min_time_tag\" es null colocar \"YR\"\n",
    "- ##### Si la columna \"year\" es null, y las columnas \"min_time_rating\" y \"min_time_tag\" son distintas de null:\n",
    "    - ##### Si \"min_time_rating\" es menor a \"min_time_tag\" colocar \"YR\"\n",
    "    - ##### Si \"min_time_tag\" es menor a \"min_time_rating\" colocar \"YT\"\n",
    "    - ##### Si \"min_time_tag\" es igual a \"min_time_rating\" colocar \"YRT\"\n",
    "- ##### En cualquier otro caso mantener \"YU\"\n",
    "##### Al finalizar este proceso eliminar las columnas \"min_time_rating\" y \"min_time_tag\"\n",
    "- Para resolver estos ejercicios podrías utilizar la función year -> https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.year.html#pyspark.sql.functions.year\n",
    "##### Este proceso se desarrollará en un método con la firma: def getLastMoviesDf(df: DataFrame): DataFrame\n",
    "##### La estructura del dataframe de salida será:\n",
    "* |-- movie_id: string\n",
    "* |-- title: string\n",
    "* |-- avg_rating: double\n",
    "* |-- count_rating: long\n",
    "* |-- stddev_rating: double\n",
    "* |-- genres: array\n",
    "* |--- |-- element: string\n",
    "* |-- tag_count: array\n",
    "* |--- |-- element: struct\n",
    "* |--- |--- |tag: string\n",
    "* |--- |--- |count: long\n",
    "* |-- year: integer\n",
    "* |-- year_type: string\n",
    "##### NO UTILIZAR withColumn NI withColumnRenamed NI UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ae848a85-c931-4c17-bed3-6c1981573395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getLastMoviesDf: (df: org.apache.spark.sql.DataFrame)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// TU CODIGO VA EN ESTA CELDA:\n",
    "\n",
    "def getLastMoviesDf(df: DataFrame): DataFrame = {\n",
    "    val null_year = f.col(\"year\").isNull\n",
    "    val null_mt_rat = f.col(\"min_time_rating\").isNull\n",
    "    val null_mt_tag = f.col(\"min_time_tag\").isNull\n",
    "    val not_null_mt_rat = f.col(\"min_time_rating\").isNotNull\n",
    "    val not_null_mt_tag = f.col(\"min_time_tag\").isNotNull\n",
    "    val año_mttag = f.year(f.col(\"min_time_tag\"))\n",
    "    val año_mtrat = f.year(f.col(\"min_time_rating\"))\n",
    "    \n",
    "    val year_nulo = df.filter(null_year)\n",
    "        .select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.col(\"title\"),\n",
    "            f.col(\"avg_rating\"),\n",
    "            f.col(\"count_rating\"),\n",
    "            f.col(\"stddev_rating\"),\n",
    "            f.col(\"genres\"),\n",
    "            f.col(\"tag_count\"),\n",
    "            f.when(null_mt_rat && not_null_mt_tag, año_mttag)\n",
    "                .when(null_mt_tag && not_null_mt_rat, año_mtrat)\n",
    "                .when(not_null_mt_rat && not_null_mt_tag, f.least(f.year(f.col(\"min_time_rating\")), f.year(f.col(\"min_time_tag\"))))\n",
    "                .otherwise(1970).alias(\"year\"),\n",
    "            f.when(((not_null_mt_rat && not_null_mt_tag) && (f.year(f.col(\"min_time_rating\")) < f.year(f.col(\"min_time_tag\")))) || null_mt_tag, \n",
    "                   f.lit(\"YR\").alias(\"year_type\"))\n",
    "                .when(((not_null_mt_rat && not_null_mt_tag) && (f.year(f.col(\"min_time_tag\")) < f.year(f.col(\"min_time_rating\")))) || null_mt_rat, \n",
    "                      f.lit(\"YT\").alias(\"year_type\"))\n",
    "                .when(f.year(f.col(\"min_time_rating\")) === f.year(f.col(\"min_time_tag\")), f.lit(\"YRT\").alias(\"year_type\"))\n",
    "                .otherwise(f.lit(\"YU\")).alias(\"year_type\")\n",
    "        ).drop(\"min_time_rating\", \"min_time_tag\")\n",
    "    \n",
    "    val year_no_nulo = df.filter(f.col(\"year\").isNotNull)\n",
    "        .select(\n",
    "            f.col(\"movie_id\"),\n",
    "            f.col(\"title\"),\n",
    "            f.col(\"avg_rating\"),\n",
    "            f.col(\"count_rating\"),\n",
    "            f.col(\"stddev_rating\"),\n",
    "            f.col(\"genres\"),\n",
    "            f.col(\"tag_count\"),\n",
    "            f.col(\"year\"),\n",
    "            f.when(f.col(\"year\").isNotNull, f.lit(\"YO\").alias(\"year_type\"))\n",
    "        ).drop(\"min_time_rating\", \"min_time_tag\")\n",
    "\n",
    "    val resultDf = year_nulo.union(year_no_nulo)\n",
    "    resultDf\n",
    "}\n",
    "    //df // transformaciones a finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5fe4c44d-ed2b-46e2-b4b9-e822362648f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "Syntax Error.",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "// TEST:\n",
    "/* val moviesDf = getLastMoviesDf(finalDf)\n",
    "moviesDf.where(f.col(\"movie_id\") == 1).show(1,false)*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "68252b23-7945-4b65-9994-20980eb23889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+------------+-------------+--------------------+---------+----+---------+\n",
      "|movie_id|       title|avg_rating|count_rating|stddev_rating|              genres|tag_count|year|year_type|\n",
      "+--------+------------+----------+------------+-------------+--------------------+---------+----+---------+\n",
      "|  148093|The Republic|      2.33|           3|         0.62|[Action, Crime, T...|     null|2015|       YR|\n",
      "+--------+------------+----------+------------+-------------+--------------------+---------+----+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "moviesDf: org.apache.spark.sql.DataFrame = [movie_id: string, title: string ... 7 more fields]\r\n",
       "\"\r\n",
       "Ejemplo de salida esperada (el orden de la columnas podr?a ser distinto):\r\n",
       "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\r\n",
       "movie_id|           title|avg_rating|count_rating|stddev_rating|              genres|           tag_count|year|year_type|\r\n",
       "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\r\n",
       "       1|Toy Story (1995)|      3.89|       76813|         0.93|[Adventure, Anima...|[{1990S, 1}, {200...|1995|       YO|\r\n",
       "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "val moviesDf = getLastMoviesDf(finalDf)\n",
    "moviesDf.show(1)\n",
    "\"\"\"\n",
    "Ejemplo de salida esperada (el orden de la columnas podría ser distinto):\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "|movie_id|           title|avg_rating|count_rating|stddev_rating|              genres|           tag_count|year|year_type|\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "|       1|Toy Story (1995)|      3.89|       76813|         0.93|[Adventure, Anima...|[{1990S, 1}, {200...|1995|       YO|\n",
    "+--------+----------------+----------+------------+-------------+--------------------+--------------------+----+---------+\n",
    "only showing top 1 row\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdfe845e-3491-4366-8759-49d8eae1b028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expectedSchema = movie_id STRING,title STRING,avg_rating DOUBLE,count_rating BIGINT,stddev_rating DOUBLE,genres ARRAY<STRING>,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,year INT,year_type STRING\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "expectedRow: org.apache.spark.sql.Row = [179479,Samadhi Part 1: Maya, the Illusion of the Self,4.19,8,0.75,List(Documentary),List([EASTERN PHILOSOPHY,1], [MEDITATION,1], [METAPHYSICAL,1], [NEW AGE,1], [SPIRITUAL,1]),2017,YT]\r\n",
       "expectedCountByYearType: Seq[org.apache.spark.sql.Row] = List([YO,79235], [YR,159], [YRT,55], [YT,28])\r\n",
       "expectedColumns: Seq[String] = List(movie_id, title, avg_rating, count_rating, stddev_rating, genres, tag_count, year, year_type)\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "movie_id STRING,title STRING,avg_rating DOUBLE,count_rating BIGINT,stddev_rating DOUBLE,genres ARRAY<STRING>,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,year INT,year_type STRING"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "\n",
    "import java.sql.Timestamp\n",
    "\n",
    "val expectedRow = Row(\"179479\",\n",
    "                      \"Samadhi Part 1: Maya, the Illusion of the Self\",\n",
    "                      4.19,\n",
    "                      8,\n",
    "                      0.75,\n",
    "                      Seq(\"Documentary\"),\n",
    "                      Seq(Row(\"EASTERN PHILOSOPHY\", 1),\n",
    "                          Row(\"MEDITATION\", 1),\n",
    "                          Row(\"METAPHYSICAL\", 1),\n",
    "                          Row(\"NEW AGE\", 1),\n",
    "                          Row(\"SPIRITUAL\", 1)),\n",
    "                      2017,\n",
    "                      \"YT\")\n",
    "\n",
    "val expectedCountByYearType = Seq(Row(\"YO\", 79235L),\n",
    "                                  Row(\"YR\", 159L),\n",
    "                                  Row(\"YRT\", 55L),\n",
    "                                  Row(\"YT\", 28L))\n",
    "\n",
    "val expectedColumns = Seq(\"movie_id\",\"title\",\"avg_rating\",\"count_rating\",\"stddev_rating\",\"genres\",\"tag_count\",\"year\",\"year_type\")\n",
    "\n",
    "val expectedSchema = \"movie_id STRING,title STRING,avg_rating DOUBLE,count_rating BIGINT,stddev_rating DOUBLE,genres ARRAY<STRING>,tag_count ARRAY<STRUCT<tag: STRING, count: BIGINT>>,year INT,year_type STRING\"\n",
    "\n",
    "assert(moviesDf.columns.diff(expectedColumns).size + expectedColumns.diff(moviesDf.columns).size == 0)\n",
    "assert(moviesDf.filter(f.col(\"year\").isNull).count() == 0)\n",
    "assert(moviesDf\n",
    "    .select(expectedColumns.map(f.col):_*)\n",
    "    .filter(f.col(\"movie_id\") === \"179479\")\n",
    "    .collect()(0) == expectedRow)\n",
    "assert(schema_to_ddl(moviesDf.select(expectedColumns.map(f.col):_*)) == expectedSchema)\n",
    "\n",
    "moviesDf.groupBy(f.col(\"year_type\")).count().orderBy(f.col(\"count\").desc).collect()\n",
    "    .zip(expectedCountByYearType)\n",
    "    .foreach(tuple => {\n",
    "        assert(tuple._1.getAs[String](\"year_type\") == tuple._2.getAs[String](0))\n",
    "        assert(tuple._1.getAs[Long](\"count\") == tuple._2.getAs[Long](1))\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "195f87e6-bdcf-4567-a8fe-56d4f1aa36fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfs = List(([movie_id: string, title: string ... 7 more fields],08/movies))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "List(([movie_id: string, title: string ... 7 more fields],08/movies))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// NO MODIFICAR EL CONTENIDO DE ESTA CELDA\n",
    "val dfs = Seq((moviesDf, \"08/movies\"))\n",
    "\n",
    "writeTmpDf(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31a9ac-5552-4e0c-bd94-7f9b92591f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
