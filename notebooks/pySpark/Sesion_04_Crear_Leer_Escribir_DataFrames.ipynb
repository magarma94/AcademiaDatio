{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310df0be-54f1-4ae6-a179-67e407d8a1ad",
   "metadata": {},
   "source": [
    "- #### SparSession\n",
    "- #### Leer Dataframe\n",
    "- #### Esquema de un Dataframe\n",
    "- #### Crear Dataframe\n",
    "- #### Escribir Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696bd9c1-3daf-4cb7-891a-e14f2ed8a6a8",
   "metadata": {},
   "source": [
    "## Hands on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aada02ed-6ee5-4c80-a4f9-9e980d298398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f52074d-797e-4418-a715-57e9072f94d3",
   "metadata": {},
   "source": [
    "### SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e4f019-9285-465f-a7a0-b287ad778ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"sesion_1\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269aa5f5-a2b1-4e5c-a4c2-478ccb105244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://23LAP5CD20860NP.indra.es:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>sesion_1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b9cb5190a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bb0a3-fe80-487e-8a40-9af923b8e0e7",
   "metadata": {},
   "source": [
    "### Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf402d48-429e-4dd7-95dc-79dcf88b169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----+---------+----------+-----+\n",
      "|cod_client| nombre|edad|provincia|cod_postal|  vip|\n",
      "+----------+-------+----+---------+----------+-----+\n",
      "|     00001|  Julen|  31| Valencia|     23700|false|\n",
      "|     00002| Javier|  58|     Jaén|     08728| true|\n",
      "|     00003| Carlos|  48|  Sevilla|     28757| true|\n",
      "|     00004|  Maria|  38|   Gerona|     18393| true|\n",
      "|     00005|Ernesto|  22|  Cáceres|     13950|false|\n",
      "|     00006|  Luisa|  43|   Murcia|     23940| true|\n",
      "|     00007|   Raul|  51|    Álava|     09030|false|\n",
      "+----------+-------+----+---------+----------+-----+\n",
      "\n",
      "+-------+-----------+------------+----------+------+\n",
      "|cod_iuc|cod_titular|cod_producto|  fec_alta|activo|\n",
      "+-------+-----------+------------+----------+------+\n",
      "|  30000|      00006|         100|2012-05-01|  true|\n",
      "|  30001|      00006|         200|2014-05-01|  true|\n",
      "|  30002|      00006|         300|2006-02-01| false|\n",
      "|  30003|      00006|         150|2012-05-01|  true|\n",
      "|  30002|      00005|         300|2012-05-01|  true|\n",
      "|  30004|      00006|         400|2012-05-01| false|\n",
      "|  30005|      00006|         500|2012-05-01|  true|\n",
      "|  30006|      00006|         600|2012-05-01| false|\n",
      "|  30003|      00003|         150|2019-10-14|  true|\n",
      "|  30007|      00006|         700|2014-02-01| false|\n",
      "|  30008|      00006|         800|2012-05-01|  true|\n",
      "|  30009|      00006|         900|2015-09-01|  true|\n",
      "|  30009|      00002|         900|2009-10-01|  true|\n",
      "|  30010|      00006|        1000|2014-02-01|  true|\n",
      "|  30003|      00002|         150|2018-09-18|  true|\n",
      "|  30011|      00003|        1100|2018-10-01|  true|\n",
      "|  30007|      00006|         700|2012-05-01|  true|\n",
      "|  30007|      00002|         700|2015-05-15|  true|\n",
      "|  30002|      00007|         300|2001-04-11| false|\n",
      "|  30001|      00004|         200|2017-12-01|  true|\n",
      "+-------+-----------+------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+-----------------+\n",
      "|cod_producto|    desc_producto|\n",
      "+------------+-----------------+\n",
      "|         100|  tarjeta crédito|\n",
      "|         150|   tarjeta débito|\n",
      "|         200|préstamo personal|\n",
      "|         300|         hipoteca|\n",
      "|         400|plan de pensiones|\n",
      "|         500|            fondo|\n",
      "|         600|      seguro moto|\n",
      "|         700|     seguro coche|\n",
      "|         800|           nomina|\n",
      "|         900|    seguro ahorro|\n",
      "|        1000|         depósito|\n",
      "|        1100|          pension|\n",
      "+------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_csv(path):\n",
    "    return spark.read\\\n",
    "        .option(\"header\",\"true\")\\\n",
    "        .option(\"delimiter\",\",\")\\\n",
    "        .option(\"inferSchema\",\"false\")\\\n",
    "        .csv(path)\n",
    "## InferSchema ayuda para que pySpark clasifique o infiera el tipo de valor que es cada dato (\"inferSchema\",\"true\")\n",
    "\n",
    "def read_parquet(path):\n",
    "    return spark.read\\\n",
    "        .parquet(path)\n",
    "## Los archivos parquet ya tiene embebido un esquema, no tienen delimitador y tampoco podemos decir que tienen una cabecera\n",
    "\n",
    "base_path = \"../../resources/data/csv/\"\n",
    "clients_df = read_csv(base_path + \"clients.csv\")\n",
    "contracts_df = read_csv(base_path + \"contracts.csv\")\n",
    "products_df = read_csv(base_path + \"products.csv\")\n",
    "\n",
    "clients_df.show()\n",
    "contracts_df.show()\n",
    "products_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b57aac4-0e63-4d3a-8270-20bce1520794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cod_client: string (nullable = true)\n",
      " |-- nombre: string (nullable = true)\n",
      " |-- edad: string (nullable = true)\n",
      " |-- provincia: string (nullable = true)\n",
      " |-- cod_postal: string (nullable = true)\n",
      " |-- vip: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cod_client', 'nombre', 'edad', 'provincia', 'cod_postal', 'vip']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_df.printSchema()\n",
    "clients_df.columns\n",
    "## con el uso del comando X_df.columns te despliega las columnas, para saber el conteo total de columnas len(X_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea351534-8199-4be5-8812-d1f9cb34f94b",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c796ef7-9e33-417c-b709-74dc2c75f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|cod_client|          fecha_pago|\n",
      "+----------+--------------------+\n",
      "|     00001|[2020-01-01, 2022...|\n",
      "|     00002|[2022-01-01, 2023...|\n",
      "+----------+--------------------+\n",
      "\n",
      "root\n",
      " |-- cod_client: string (nullable = true)\n",
      " |-- fecha_pago: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    Row(\"00001\", [\"2020-01-01\", \"2022-01-01\"]),\n",
    "    Row(\"00002\", [\"2022-01-01\", \"2023-01-01\", \"2010-01-01\"])\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"cod_client\", StringType()),\n",
    "    StructField(\"fecha_pago\", ArrayType(StringType()))\n",
    "])\n",
    "\n",
    "pagos_df = spark.createDataFrame(data, schema)\n",
    "\n",
    "pagos_df.show()\n",
    "pagos_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e7b37-47b9-4145-b558-79d858d067fb",
   "metadata": {},
   "source": [
    "### Write Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8230e7ba-ec6a-4b68-9ac2-82dbbb3fc4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_parquet = \"../../resources/data/parquet/\"\n",
    "clients_df.write.mode(\"overwrite\").parquet(base_path_parquet + \"clients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fcdb6-2bf7-46bb-8090-8004038c9c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
