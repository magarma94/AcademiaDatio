{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a491a835-7add-4f73-9cb9-f5c7689e555b",
   "metadata": {},
   "source": [
    "- #### Transformaciones\n",
    "    - ##### Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6956efa9-7ad7-4446-94c1-e2c207fcf290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sc = org.apache.spark.SparkContext@7d62aa27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@31aaaf31\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@7d62aa27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{SparkSession, DataFrame}\n",
    "\n",
    "val spark = SparkSession.builder\n",
    "        .appName(\"sesion_1\")\n",
    "        .master(\"local[*]\")\n",
    "        .getOrCreate()\n",
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4721001-1898-490c-adb4-aecf9ce2b2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Some(http://23LAP5CD20860NP.indra.es:4040)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.uiWebUrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b206961-7a2a-433f-895e-26834d4cf524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+----------+------+\n",
      "|cod_iuc|cod_titular|cod_producto|  fec_alta|activo|\n",
      "+-------+-----------+------------+----------+------+\n",
      "|  30000|      00006|         100|2012-05-01|  true|\n",
      "|  30001|      00006|         200|2014-05-01|  true|\n",
      "|  30002|      00006|         300|2006-02-01| false|\n",
      "|  30003|      00006|         150|2012-05-01|  true|\n",
      "|  30002|      00005|         300|2012-05-01|  true|\n",
      "|  30004|      00006|         400|2012-05-01| false|\n",
      "|  30005|      00006|         500|2012-05-01|  true|\n",
      "|  30006|      00006|         600|2012-05-01| false|\n",
      "|  30003|      00003|         150|2019-10-14|  true|\n",
      "|  30007|      00006|         700|2014-02-01| false|\n",
      "|  30008|      00006|         800|2012-05-01|  true|\n",
      "|  30009|      00006|         900|2015-09-01|  true|\n",
      "|  30009|      00002|         900|2009-10-01|  true|\n",
      "|  30010|      00006|        1000|2014-02-01|  true|\n",
      "|  30003|      00002|         150|2018-09-18|  true|\n",
      "|  30011|      00003|        1100|2018-10-01|  true|\n",
      "|  30007|      00006|         700|2012-05-01|  true|\n",
      "|  30007|      00002|         700|2015-05-15|  true|\n",
      "|  30002|      00007|         300|2001-04-11| false|\n",
      "|  30001|      00004|         200|2017-12-01|  true|\n",
      "+-------+-----------+------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "contractsDf = [cod_iuc: string, cod_titular: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "readCsv: (path: String)org.apache.spark.sql.DataFrame\r\n",
       "BasePath: String = ../../resources/data/csv/\r\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "[cod_iuc: string, cod_titular: string ... 3 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readCsv(path: String): DataFrame = {\n",
    "    spark.read\n",
    "        .option(\"header\",\"true\")\n",
    "        .option(\"delimiter\",\",\")\n",
    "        .option(\"inferSchema\",\"false\")\n",
    "        .csv(path)\n",
    "}\n",
    "\n",
    "val BasePath = \"../../resources/data/csv/\"\n",
    "val contractsDf = readCsv(BasePath + \"contracts.csv\")\n",
    "contractsDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2b5b9-8eb1-46cb-8dc1-58a66fb82282",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Windows\n",
    "    // Agregacion -> max, min, count, avg, mean, sum, ...\n",
    "    // Ranking -> row_number, rank, dense_rank, ...\n",
    "    // lag lead\n",
    "\n",
    "import org.apache.spark.sql.expressions.{Window, WindowSpec}\n",
    "import org.apache.spark.sql.{functions => f}\n",
    "\n",
    "contractsDf.orderBy(f.col(\"cod_iuc\")).show()\n",
    "\n",
    "val window_1: WindowSpec = Window.partitionBy(f.col(\"cod_iuc\"))\n",
    "val window_2: WindowSpec = Window.partitionBy(f.col(\"cod_iuc\")).orderBy(f.col(\"fec_alta\").asc)\n",
    "\n",
    "\n",
    "contractsDf.select(\n",
    "    contractsDf.columns.map(f.col) :+\n",
    "    f.count(\"*\").over(window_1).alias(\"count_w\") :+\n",
    "    f.max(f.col(\"fec_alta\")).over(window_2).alias(\"max_fec_alta_w\") :+\n",
    "    f.sum(f.col(\"cod_producto\")).over(window_2).alias(\"sum_cod_producto_w\") :_*\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e506d-a5fc-4908-a681-e7ed365a94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractsDf.orderBy(f.col(\"cod_iuc\")).show()\n",
    "\n",
    "val window_3: WindowSpec = Window.partitionBy(f.col(\"cod_iuc\")).orderBy(f.col(\"cod_titular\").asc)\n",
    "\n",
    "contractsDf.select(\n",
    "    contractsDf.columns.map(f.col) :+\n",
    "    f.row_number().over(window_3).alias(\"row_number\") :+\n",
    "    f.rank().over(window_3).alias(\"rank\") :+\n",
    "    f.dense_rank().over(window_3).alias(\"dense_rank\") :_*\n",
    ").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a67d5c-ca6b-4606-a00c-a9cda6d5a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractsDf.orderBy(f.col(\"cod_iuc\")).show()\n",
    "\n",
    "val window_4: WindowSpec = Window.partitionBy(f.col(\"cod_iuc\")).orderBy(f.col(\"fec_alta\").desc)\n",
    "\n",
    "contractsDf.select(\n",
    "    contractsDf.columns.map(f.col) :+\n",
    "    f.lag(f.col(\"fec_alta\"), 1, \"1970-01-01\").over(window_4).alias(\"lag\") :+\n",
    "    f.lead(f.col(\"fec_alta\"), 1, \"1970-01-01\").over(window_4).alias(\"lead\") :_*\n",
    ").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c9f7c-4cee-4f39-ad0c-f8cb32a4d57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
